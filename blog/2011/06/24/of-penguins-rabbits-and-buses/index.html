<!DOCTYPE html> <html class=no-js lang=en> <head> <meta charset=utf-8> <meta content='width=device-width, initial-scale=1.0' name=viewport> <meta content='IE=edge,chrome=1' http-equiv=X-UA-Compatible> <title>Of Penguins, Rabbits and Buses</title> <link href="/assets/stylesheets/app-3d04c269.css" rel=stylesheet /> <script src="/assets/javascripts/modernizr-84a49412.js"></script> <link href='/assets/images/favicon.ico' rel='shortcut icon'> </head> <body class='blog blog_2011 blog_2011_06 blog_2011_06_24 blog_2011_06_24_of-penguins-rabbits-and-buses blog_2011_06_24_of-penguins-rabbits-and-buses_index f-topbar-fixed'> <div class='fixed raised'> <nav class=top-bar data-topbar role=navigation> <ul class=title-area> <li class=name> <h1> <a href='/'> <img alt="Agora Games" class=main-logo src="/assets/images/agoragames-new-8534f601.svg"/> </a> </h1> </li> <li class='toggle-topbar menu-icon'> <a href='javascript:void(0)'> <span>Menu</span> </a> </li> </ul> <section class=top-bar-section> <ul class=right> <li> <a data-anchor href='/#about'>About</a> </li> <li> <a data-anchor href='/#team'>Team</a> </li> <li> <a data-anchor href='/#contact'>Contact</a> </li> <li> <a href='/careers'>Careers</a> </li> <li> <a href='/blog'>Blog</a> </li> <li class=hydra-theme> <a href='http://hydra.agoragames.com'> <img alt=Hydra width=92 src="/assets/images/hydra-wordmark-6248cf07.svg"/> </a> </li> </ul> </section> </nav> </div> <div class=row> <div class=columns> <h1 class=blog-page-title> <a href="/blog">The <strong>Blog</strong> </a></h1> </div> </div> <div class=row> <div class='columns large-9'> <h2 class=blog__title> <a href="/blog/2011/06/24/of-penguins-rabbits-and-buses/">Of Penguins, Rabbits and Buses</a> </h2> <div class=blog__author> By <strong>Aaron Westendorf</strong> </div> <div class=blog__date> Friday, June 24, 2011 </div> <div class=blog__body> <p>Here at Agora we make use of dedicated hardware and virtual machines running on our providers' respective clouds. In recent months, we've moved our RabbitMQ hosts onto hardware because we found that we could far exceed the CPU capacity of our virtual machines and it was far cheaper to run a small cluster of hardware hosts than a giant cluster of VMs. We used an existing, underutilized host for our primary traffic while awaiting delivery and installation of a new pair servers. Expecting a simple plug-and-play swap, I set out to test the new hardware before we made the transition. What follows is a harrowing tale into the deepest depths of modern hardware architecture.</p> <p>Our current primary RabbitMQ host, leviathan, is a 24 core Intel Xeon X5650 running at 2.67GHz and fitted with 132GB of RAM. The machine hosts all our in-memory databases, such as Redis and Memcached, and is vastly underutilized at this time. RabbitMQ is run in a cluster with other nodes hosted on VMs to give us failover capacity.</p> <p>To replace its role as RabbitMQ host, we purchased artemis and hermes, two 24 core AMD Opteron 6172s running at 2.1GHz and fitted with 8GB of RAM each. Recent versions of RabbitMQ page queue backlogs to disk, and our traffic pattern and infrastructure validations are such that this amount or RAM is sufficient.</p> <p>At first, one might assume that the differences in processors would result in near-equal <a href="http://www.bit-tech.net/hardware/cpus/2010/03/31/amd-opteron-6174-vs-intel-xeon-x5650-review/1">performance</a> for RabbitMQ. The Intel CPUs have faster clock cycles, but they rely on Hyper-Threading to present 24 logical cores to the operating system. The AMD CPUs are slower, but they present 24 hardware cores to the kernel. <a href="http://www.centos.org/docs/5/html/5.2/Deployment_Guide/s2-proc-cpuinfo.html">Linux</a> reports 5333 bogomips for the Xeons, 4200 for the Opterons.</p> <p>Using <a href="https://github.com/agoragames/haigha">haigha</a>'s load testing <a href="https://github.com/agoragames/haigha/blob/master/scripts/stress_test">script</a>, we were astonished to discover that our brand-new hardware was almost 50% slower than our until-recently-brand-new Intel hardware! What could possibly have gone wrong?</p> <p>The test that we ran consisted of 3 VM clients, each with 4 cores, each running 3 instances of the standard configuration of the <code>stress_test</code> script of 500 channels looping messages over 500 queues. That is, 4500 channels and queues, each channel publishing a message as soon as it receives its previously published message. The test would run for a fixed period of time, usually a minute.</p> <p>Our investigation started simple enough. Using top and our new favorite, htop, we observed that the kernel was using a substantial portion of each cores capacity. We also observed that cores were underutilized, as htop clearly showed a visible gap on the right-hand side the CPU graphs. Though not scientific, it appeared to be a 10-30% loss. A bit of <a href="http://www.theregister.co.uk/2010/04/20/ubuntu_server_10_04/">research</a> implied that the Ubuntu 10.04.2 kernel, 2.6.32, was perhaps released around the same time as our AMD chips, and may not fully support them. We tested the latest patches to that release, 2.6.32-32, but did not observe any improvement.</p> <p>Venturing into unknown territory, we installed the latest kernel backported from maverick, 2.6.35-25. We immediately observed an improvement in CPU usage, such that all cores were near 100% utilization. Sadly though, our message throughput remained nearly the same, as user space consumed only 40% of each core. Yet when comparing a single instance of <code>stress_test</code> , leviathan and artemis performed nearly equal. In no case were we able to induce any IO wait, which was to be expected since we weren't hitting disk. Why would 24 cores of AMD be so dramatically different than 24 cores of Intel?</p> <p>With the obvious problems ruled out and the latest kernel installed, I started to dig deeper into the architectural differences between the two companies' designs. Using <a href="http://manpages.ubuntu.com/manpages/natty/man1/lscpu.1.html">lscpu</a>, we can see two very different CPU designs.</p> <p>``` leviathan:~$ lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit CPU(s): 24 Thread(s) per core: 2 Core(s) per socket: 6 CPU socket(s): 2 NUMA node(s): 2 Vendor ID: GenuineIntel CPU family: 6 Model: 44 Stepping: 2 CPU MHz: 2666.806 Virtualization: VT-x L1d cache: 32K L1i cache: 32K L2 cache: 256K L3 cache: 12288K</p> <p>artemis:~$ lscpu Architecture: x86_64 CPU op-mode(s): 64-bit CPU(s): 24 Thread(s) per core: 1 Core(s) per socket: 12 CPU socket(s): 2 NUMA node(s): 4 Vendor ID: AuthenticAMD CPU family: 16 Model: 9 Stepping: 1 CPU MHz: 2100.172 Virtualization: AMD-V L1d cache: 64K L1i cache: 64K L2 cache: 512K L3 cache: 5118K ```</p> <p>The AMD CPUs have nearly double the amount of dedicated cache per core, but a much smaller (shared) L3 cache. Though this was clearly a fundamental difference, it did not seem adequate in explaining the vast amount of time that the kernel was consuming on each CPU. Yet the only reason why the kernel would be consuming so much time, without any IO wait, would be if it was waiting for something. What would Linux be waiting for that Intel was readily delivering?</p> <p>As I noted, our test was running 4500 unique channels and queues. In a <a href="http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/2011-May/012991.html">reply</a> to a recent inquiry on the RabbitMQ mailing list, I learned that both channels and queues are allocated an Erlang process. A bit of searching and I found a useful <a href="http://www.erlang.org/euc/08/euc_smp.pdf">paper</a>[PDF] on the early SMP support in Erlang R12B, circa 2008. The diagrams show a single run queue from which all schedulers pull the next process to run.</p> <p>By R13B, each scheduler had a <a href="http://www.erlang.org/documentation/doc-5.7/doc/highlights.html">dedicated</a> run queue, vastly decreasing lock contention. Additionally, scheduling algorithms, and <a href="http://www.erlang.org/doc/man/erlang.html#system_flag-2">configuration thereof</a>, were designed specifically to take advantage of the variety of SMP architectures. RabbitMQ is running on R14B01, and so it should have the latest in SMP optimizations, particularly with respect to <a href="http://en.wikipedia.org/wiki/Non-Uniform_Memory_Access">NUMA</a>, which is how both Intel and AMD implement their SMP architectures.</p> <p>Linux is also NUMA-aware, and contains scheduling algorithms that try to pair the core that a process or thread will use with the NUMA node where its memory is allocated. Likewise, it tries to allocate memory on the same NUMA node as the process or thread that is requesting it. This was a topic area we were already familiar with, but in terms of <a href="http://jcole.us/blog/archives/2010/09/28/mysql-swap-insanity-and-the-numa-architecture/">database applications</a> that consume most of system RAM. That clearly was not the case here, as RabbitMQ barely consumed 500MB under the stress test, and the memory is allocated on demand, and so was spread evenly across all NUMA nodes.</p> <p>So with hardware that benchmarked well, using recent releases of the Linux kernel and Erlang VM, and an application that used a small fraction of available RAM, RabbitMQ performed abysmally slow. What could possibly cause such behavior?</p> <p>The final piece of the puzzle lay in the nature of RabbitMQ itself. Though Erlang may try to pair a process with a node-bound scheduler, and Linux allocate memory on the same node as that scheduler, that's of little use in practice. When a message is read from a connection (itself a process) on a channel (also a process), the route of that message must be looked up in an mnesia-backed global table to determine which queue(s) the message should be copied to. Bits are allocated and written to for that queue (yet another process), and then any consumer of that queue - a channel - must read the bits before sending them out. In short, there is a near-0 chance that the bits necessary to fulfill a single publish-route-consume will be processed by the same scheduler, and a just-slightly-greater-than-0 chance that it will be processed by a scheduler on the same NUMA node. Even if the code is optimized to only copy messages as references, numerous reads and writes must acquire an exclusive lock on a NUMA nodes memory bus.</p> <p>So what's the difference between Intel and AMD NUMA implementations?</p> <p>``` leviathan:~$ numactl -H available: 2 nodes (0-1) node 0 cpus: 0 2 4 6 8 10 12 14 16 18 20 22 node 0 size: 65525 MB node 0 free: 59013 MB node 1 cpus: 1 3 5 7 9 11 13 15 17 19 21 23 node 1 size: 65535 MB node 1 free: 59787 MB node distances: node 0 1 0: 10 20 1: 20 10</p> <p>artemis:~$ numactl -H available: 4 nodes (0-3) node 0 cpus: 0 2 4 6 8 10 node 0 size: 2047 MB node 0 free: 1621 MB node 1 cpus: 12 14 16 18 20 22 node 1 size: 2044 MB node 1 free: 1758 MB node 2 cpus: 13 15 17 19 21 23 node 2 size: 2048 MB node 2 free: 1806 MB node 3 cpus: 1 3 5 7 9 11 node 3 size: 2047 MB node 3 free: 1874 MB node distances: node 0 1 2 3 0: 10 20 20 20 1: 20 10 20 20 2: 20 20 10 20 3: 20 20 20 10 ```</p> <p>The AMD cores are split across four nodes, whereas the Intel cores only use two. In the case where a process uses all cores equally, there is a 50% probability of a memory operation being local on a Xeon processor, but only a 25% probability on an Opteron!</p> <p>Starting RabbitMQ on just 2 nodes, I instantly gained nearly 30% improvement, using half the available processing power, and kernel time dropped to a far more normal 20-30% per core. I experimented with this for a few hours, and found that 3 nodes, with memory interleave across all 4 nodes, was the optimal configuration. But what of the Erlang scheduler?</p> <p>``` artemis:~$ erl Erlang R14B01 (erts-5.8.2) [source] [64-bit] [smp:24:24] [rq:24] [async-threads:0] [hipe] [kernel-poll:false]</p> <p>Eshell V5.8.2 (abort with ^G) 1&gt; erlang:system_info(scheduler_bind_type). thread_no_node_processor_spread ```</p> <p>Erlang is smart enough to recognize that this is a NUMA system, but the scant documentation implies that the default scheduler type is best suited to to Hyper-Threading architectures. As it turns out though, all of the scheduler types that are documented as designed for NUMA were slower than the simple <code>processor_spread</code> scheduler, which out-performed the NUMA schedulers by almost 30%. And what of the number of schedulers and <a href="http://stackoverflow.com/questions/1182025/what-do-the-erlang-emulator-info-statements-mean">request queues</a>? Though they're configured for 24 cores, experiments show that the default number of 24 is best, even given only 18 cores of execution. I can't speak to why exactly either of these two settings are best, but I can entertain any number of educated guesses.</p> <p>The last question that remained was, if we're to run with 3 out of 4 NUMA nodes, which ones do we choose? It seemed logical to pick the ones that weren't connected directly to the network card, the only other bit of hardware which we were trying to push as many bits through as possible.</p> <p>``` artemis:~$ lspci -tv -[0000:00]-+-00.0 ATI Technologies Inc RD890 Northbridge only dual slot (2x16) PCI-e GFX Hydra part +-04.0-[0000:04]–+-00.0 Broadcom Corporation NetXtreme II BCM5709 Gigabit Ethernet | -00.1 Broadcom Corporation NetXtreme II BCM5709 Gigabit Ethernet +-06.0-[0000:05]–+-00.0 Broadcom Corporation NetXtreme II BCM5709 Gigabit Ethernet | -00.1 Broadcom Corporation NetXtreme II BCM5709 Gigabit Ethernet ………………….</p> <p>artemis:~$ ifconfig eth1 Link encap:Ethernet HWaddr aa:aa:aa:aa:aa:aa inet addr:111.111.111.111 Bcast:111.111.111.111 Mask:255.255.255.255 inet6 addr: ffff::ffff:ffff:ffff:ffff/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:71583284 errors:0 dropped:0 overruns:0 frame:0 TX packets:134508244 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:13852822249 (13.8 GB) TX bytes:23156900853 (23.1 GB) Interrupt:45 Memory:f4000000-f4012800</p> <p>artemis:~$ cat /sys/bus/pci/devices/0000:04:00.1/irq 45</p> <p>artemis:~$ cat /sys/bus/pci/devices/0000:04:00.1/numa_node 0 ```</p> <p>It's unclear how much of a difference that makes, but when RabbitMQ is under full load, a few of the cores on node 0 show 5-30% kernel usage, a mixture of network card and memory traffic.</p> <p>Our final configuration looks something like this. Your installation will have these stanzas in various places depending on the distribution and how your administrator configured the runtime scripts. Note that we turned off <a href="http://www.erlang-solutions.com/thesis/tcp_optimisation/tcp_optimisation.html">async threads</a>. We didn't observe any benefit of enabling them, and it was unclear if they degraded performance.</p> <p><code> SERVER_ERL_ARGS="+K true +sbtps +P 10485760" exec setuidgid rabbitmq numactl --cpunodebind=!0 /usr/local/sbin/rabbitmq-server </code></p> <p>The final result? Using only 18 AMD cores of execution, artemis achieved 93% of the performance of leviathans 24 Intel cores. Given that Linux calculated a 22% performance difference, we'll call that a win. Who can complain about two hosts capable of 40,000 messages each vs. a single host capable of 43,000?</p> <p>What can we learn from this? Firstly, know the hardware you're buying. No matter how this played out, the Intel chips benchmarked faster, and we should have stuck with those when purchasing our RabbitMQ hosts. Second, the physical layout of the data path and the nature of your application together determine the bounds of your capacity. <em>Any</em> multithreaded application configured to use all of your cores, where the memory access pattern is not localized to a single thread, will exhibit <em>non-linear</em> performance inversely proportional to the number of NUMA nodes those threads run on.</p> </div> </div> <div class='columns large-3'> <div class=blog-archives-sidebar> <h2>Blog archives</h2> <h3> <a href="/blog/2015/">2015</a> </h3> <ul> <li> <a href="/blog/2015/03/">March 2015</a> </li> <li> <a href="/blog/2015/01/">January 2015</a> </li> </ul> <h3> <a href="/blog/2014/">2014</a> </h3> <ul> <li> <a href="/blog/2014/12/">December 2014</a> </li> <li> <a href="/blog/2014/11/">November 2014</a> </li> <li> <a href="/blog/2014/10/">October 2014</a> </li> <li> <a href="/blog/2014/08/">August 2014</a> </li> <li> <a href="/blog/2014/07/">July 2014</a> </li> <li> <a href="/blog/2014/06/">June 2014</a> </li> <li> <a href="/blog/2014/04/">April 2014</a> </li> <li> <a href="/blog/2014/03/">March 2014</a> </li> <li> <a href="/blog/2014/02/">February 2014</a> </li> <li> <a href="/blog/2014/01/">January 2014</a> </li> </ul> <h3> <a href="/blog/2013/">2013</a> </h3> <ul> <li> <a href="/blog/2013/11/">November 2013</a> </li> <li> <a href="/blog/2013/10/">October 2013</a> </li> <li> <a href="/blog/2013/09/">September 2013</a> </li> <li> <a href="/blog/2013/08/">August 2013</a> </li> <li> <a href="/blog/2013/07/">July 2013</a> </li> <li> <a href="/blog/2013/06/">June 2013</a> </li> <li> <a href="/blog/2013/05/">May 2013</a> </li> <li> <a href="/blog/2013/04/">April 2013</a> </li> <li> <a href="/blog/2013/03/">March 2013</a> </li> <li> <a href="/blog/2013/02/">February 2013</a> </li> <li> <a href="/blog/2013/01/">January 2013</a> </li> </ul> <h3> <a href="/blog/2012/">2012</a> </h3> <ul> <li> <a href="/blog/2012/12/">December 2012</a> </li> <li> <a href="/blog/2012/11/">November 2012</a> </li> <li> <a href="/blog/2012/10/">October 2012</a> </li> <li> <a href="/blog/2012/09/">September 2012</a> </li> <li> <a href="/blog/2012/08/">August 2012</a> </li> <li> <a href="/blog/2012/07/">July 2012</a> </li> <li> <a href="/blog/2012/06/">June 2012</a> </li> <li> <a href="/blog/2012/05/">May 2012</a> </li> <li> <a href="/blog/2012/04/">April 2012</a> </li> <li> <a href="/blog/2012/03/">March 2012</a> </li> <li> <a href="/blog/2012/02/">February 2012</a> </li> <li> <a href="/blog/2012/01/">January 2012</a> </li> </ul> <h3> <a href="/blog/2011/">2011</a> </h3> <ul> <li> <a href="/blog/2011/10/">October 2011</a> </li> <li> <a href="/blog/2011/09/">September 2011</a> </li> <li> <a href="/blog/2011/08/">August 2011</a> </li> <li> <a href="/blog/2011/07/">July 2011</a> </li> <li> <a href="/blog/2011/06/">June 2011</a> </li> <li> <a href="/blog/2011/05/">May 2011</a> </li> <li> <a href="/blog/2011/04/">April 2011</a> </li> <li> <a href="/blog/2011/03/">March 2011</a> </li> <li> <a href="/blog/2011/02/">February 2011</a> </li> <li> <a href="/blog/2011/01/">January 2011</a> </li> </ul> <h3> <a href="/blog/2010/">2010</a> </h3> <ul> <li> <a href="/blog/2010/12/">December 2010</a> </li> <li> <a href="/blog/2010/11/">November 2010</a> </li> <li> <a href="/blog/2010/10/">October 2010</a> </li> <li> <a href="/blog/2010/09/">September 2010</a> </li> <li> <a href="/blog/2010/08/">August 2010</a> </li> <li> <a href="/blog/2010/07/">July 2010</a> </li> <li> <a href="/blog/2010/06/">June 2010</a> </li> <li> <a href="/blog/2010/05/">May 2010</a> </li> <li> <a href="/blog/2010/04/">April 2010</a> </li> <li> <a href="/blog/2010/03/">March 2010</a> </li> <li> <a href="/blog/2010/02/">February 2010</a> </li> <li> <a href="/blog/2010/01/">January 2010</a> </li> </ul> <h3> <a href="/blog/2009/">2009</a> </h3> <ul> <li> <a href="/blog/2009/12/">December 2009</a> </li> <li> <a href="/blog/2009/11/">November 2009</a> </li> <li> <a href="/blog/2009/10/">October 2009</a> </li> <li> <a href="/blog/2009/09/">September 2009</a> </li> <li> <a href="/blog/2009/08/">August 2009</a> </li> <li> <a href="/blog/2009/07/">July 2009</a> </li> <li> <a href="/blog/2009/06/">June 2009</a> </li> <li> <a href="/blog/2009/05/">May 2009</a> </li> <li> <a href="/blog/2009/04/">April 2009</a> </li> <li> <a href="/blog/2009/03/">March 2009</a> </li> <li> <a href="/blog/2009/02/">February 2009</a> </li> <li> <a href="/blog/2009/01/">January 2009</a> </li> </ul> <h3> <a href="/blog/2008/">2008</a> </h3> <ul> <li> <a href="/blog/2008/11/">November 2008</a> </li> <li> <a href="/blog/2008/10/">October 2008</a> </li> <li> <a href="/blog/2008/09/">September 2008</a> </li> <li> <a href="/blog/2008/08/">August 2008</a> </li> </ul> </div> </div> </div> <script src="/assets/javascripts/app-65d7c99d.js" async=true></script> </body> </html>