<!DOCTYPE html> <html class=no-js lang=en> <head> <meta charset=utf-8> <meta content='width=device-width, initial-scale=1.0' name=viewport> <meta content='IE=edge,chrome=1' http-equiv=X-UA-Compatible> <title>Brain Matters</title> <link href="/assets/stylesheets/app-afc0a2ef.css" rel=stylesheet /> <script src="/assets/javascripts/modernizr-84a49412.js"></script> <link href='/assets/images/favicon.ico' rel='shortcut icon'> </head> <body class='blog blog_page blog_page_24 blog_page_24_index f-topbar-fixed'> <div class='fixed raised'> <nav class=top-bar data-topbar role=navigation> <ul class=title-area> <li class=name> <h1> <a href='/'> <img alt="Agora Games" class=main-logo src="/assets/images/agoragames-new-8534f601.svg"/> </a> </h1> </li> <li class='toggle-topbar menu-icon'> <a href='javascript:void(0)'> <span>Menu</span> </a> </li> </ul> <section class=top-bar-section> <ul class=right> <li> <a data-anchor href='/#about'>About</a> </li> <li> <a data-anchor href='/#team'>Team</a> </li> <li> <a data-anchor href='/#contact'>Contact</a> </li> <li> <a href='/careers'>Careers</a> </li> <li> <a href='/blog'>Blog</a> </li> <li class=hydra-theme> <a href='http://hydra.agoragames.com'> <img alt=Hydra width=92 src="/assets/images/hydra-wordmark-6248cf07.svg"/> </a> </li> </ul> </section> </nav> </div> <div class=row> <div class=columns> <h1 class=blog-page-title> <a href="/blog">The <strong>Blog</strong> </a></h1> </div> </div> <div class=row> <div class='columns large-9'> <div class=blog-entry-list><div class=blog-entry> <div class=blog__date> Jan 15 </div> <div class=blog__contents> <h2 class=blog__title> <a href="/blog/2010/01/15/i-am-git-and-so-can-you/">I Am Git (And So Can You!)</a> </h2> <div class=blog__author> By <strong>David Czarnecki</strong> </div> <div class=blog__body> <p>It&rsquo;s amazing how a few months can change your mindset around the version control system you use. Ever since I joined Agora Games in May 2008, we have used Subversion (SVN). Subversion is a fine version control system. We have one new project using Subversion and we will probably have a few legacy projects that will always use Subversion. However, last year, one of our project teams made the switch to Git and ever since then, new projects have been using Git.</p> <p>Looking at CruiseControl, here&rsquo;s the breakdown of Subversion and Git projects:</p> <p>Subversion: 4</p> <p>Git: 7</p> <p>Here is what I found personally about my Git transition experience.</p> <ul> <li>If you look at the simple examples or cursory blog post introductions of using Git as a version control system, you&rsquo;re probably not going to switch. I didn&rsquo;t find those examples or Git blog posts enlightening at all. I just thought to myself, &ldquo;Great, Git can track changes to files just like Subversion, so why should I switch?&rdquo;.</li> <li>Git is something I can use independent of a service like GitHub locally to implement version control on projects that might never make it off of my machine.</li> <li>Git can be taken to the extreme where every &ldquo;change&rdquo; can be separated from the main branch of development and then merged at a later point. At Agora, we&rsquo;ve taken a more balanced approach where major features go into a new branch and then are reviewed and merged back into the main branch, after which the new branch can be safely removed (e.g. replacing an authentication system).</li> <li>Although tools like <a href="http://www.syntevo.com/smartgit/index.html">SmartGit</a> exist, I needed to get comfortable by using Git from the command-line.</li> <li>There are a lot of Git commands and capabilities I haven&rsquo;t used yet, and that&rsquo;s OK.</li> <li>I love the idea of the Git stash, where you can scurry away local changes and revert to a clean working directory, but then recover those changes later.</li> </ul> <p>Git is just something you need to try. I&rsquo;m no expert in Git (yet). Git&rsquo;s barrier to entry feels very minimal when compared to other version control systems.</p> <p>P.S. I realize this blog post falls under the &ldquo;cursory blog post introductions of using Git as a version control system&rdquo; category. Whatever.</p> <p>:)</p> </div> </div> </div> <div class=blog-entry> <div class=blog__date> Jan 4 </div> <div class=blog__contents> <h2 class=blog__title> <a href="/blog/2010/01/04/scaling-ruby-and-rails-part-1/">Scaling Ruby and Rails Part 1</a> </h2> <div class=blog__author> By <strong>David Czarnecki</strong> </div> <div class=blog__body> <p>I wish scaling applications and systems these days consisted solely of &ldquo; <a href="http://olabini.com/blog/2008/05/just-add-scaling/">Just Add Scaling!</a>&rdquo;. But you know what? It&rsquo;s not. I also forget where I read it, but the quote went something like, &ldquo;Programming languages don&rsquo;t scale, architectures scale.&rdquo; Scaling is driven by proper iterative design, implementation and testing.</p> <p>In a series of blog posts I want to cover how we have approached scaling out various parts of our Ruby and Rails infrastructure here at Agora Games using real-world examples on very high-traffic sites such as the Guitar Hero and Call of Duty community sites.</p> <p>Here I&rsquo;ll cover the &ldquo;Deep Dive&rdquo;. I originally came from BigCo. and there we used a concept called the &ldquo;Deep Dive&rdquo;, which involved taking a specific requirement in combination with an approach or technology and following a thread of execution that would take you through the entire technology stack, or a &ldquo;deep dive&rdquo; through the system. At the end you would either prove or disprove the technology or approach. But it was done in the context of a real set of requirements.</p> <p>The following is the e-mail (project/features names changed to protect the innocent &hellip; the important concept here is the Deep Dive, not the project/features) I sent around to our engineering team in September of last year after doing a Deep Dive on a queue system.</p> <hr> <blockquote> <p>From: David Czarnecki</p> </blockquote> <p>To: Engineering</p> <p>Clearly Defined Requirement(s)</p> <p>Ultimately, to do a deep dive correctly, you need clearly defined requirements to evaluate your technology or approach against. In the case of PROJECT X, with the use of a queue, we had the following:</p> <p>Setup queue Decide event(s) Send to queue Aggregate from/to queue Put into message creation Send back to the app</p> <p>Narrowing the Field</p> <p>I spent a day looking at various queue packages in Ruby and other languages to understand:</p> <p>Features - What features do we get out of the package? API - How easy is it to setup/create/interact with the queue from actual code? Aliveness - Is this an ongoing effort or was it thrown on RubyForge and ultimately abandoned? Community - Where is this package being used? How many developers or contributors commit to the project? Language - Are we expanding our technology stack by introducing a queue written in one language with an interface in another language?</p> <p>Pork, aka The Other Other Requirements</p> <p>And don&rsquo;t forget about the other &ldquo;unspoken&rdquo; requirements.</p> <p>Ease of setup Speed Failsafe Scaling</p> <p>At the end of the day, whichever package is picked, you want some guarantee that the package you&rsquo;ve chosen is &ldquo;good&rdquo; or at least &ldquo;good enough&rdquo;. But what if the Guarantee Fairy&rsquo;s a crazy glue sniffer? Next thing you know there&rsquo;s change missing from your dresser and your daughter&rsquo;s knocked up. I&rsquo;ve seen it a hundred times. Although you&rsquo;ve got a set of requirements that define how you&rsquo;re going to use a technology or approach operationally, there are still requirements that need to be addressed, even if there isn&rsquo;t anything formally specified.</p> <p>Let&rsquo;s Get Ready To Rumble</p> <p>I chose Sparrow and Rabbit/AMQP since these passed the &ldquo;ease of setup&rdquo; requirements with flying colors.</p> <p><a href="http://code.google.com/p/sparrow/">http://code.google.com/p/sparrow/</a> - Pure Ruby</p> <p><a href="http://hopper.squarespace.com/blog/2008/7/22/simple-amqp-library-for-ruby.html">http://hopper.squarespace.com/blog/2008/7/22/simple-amqp-library-for-ruby.html</a></p> <p>Erlang Queue Server/Ruby interface to Queue</p> <p>Next up it was time to prove out the feasibility of the two technologies looking at the &ldquo;soft&rdquo; requirements in the context of the &ldquo;hard&rdquo; requirements. This meant setting up the two systems to:</p> <p>Setup queue Send event(s) to queue Aggregate from/to queue</p> <p>The other &ldquo;hard&rdquo; requirements would be addressed based on the outcome of this initial sanity check.</p> <p>2 Queues Enter, 1 Queue Leaves &hellip; Wait, what?</p> <p>Although I wanted to use this to prove out &ldquo;FEATURE X&rdquo;, I also wanted to address its use in &ldquo;FEATURE Y&rdquo;. &ldquo;FEATURE Y&rdquo; involves converting a song file into an MP3. So I setup a test to evaluate the two systems which was:</p> <pre class="highlight ruby"><code><span class="mi">1</span><span class="n">k</span><span class="p">,</span> <span class="mi">8</span><span class="n">k</span><span class="p">,</span> <span class="mi">16</span><span class="n">k</span><span class="p">,</span> <span class="mi">32</span><span class="n">k</span><span class="p">,</span> <span class="mi">64</span><span class="n">k</span> <span class="n">messages</span> <span class="k">do</span>
  <span class="mi">25</span><span class="p">.</span><span class="nf">times</span> <span class="k">do</span>
    <span class="mi">10000</span> <span class="n">messages</span> <span class="k">do</span>
      <span class="n">publish</span> <span class="n">message</span> <span class="n">to</span> <span class="n">queue</span>
      <span class="n">read</span> <span class="n">message</span> <span class="n">from</span> <span class="n">queue</span>
    <span class="k">end</span>
  <span class="k">end</span>
<span class="k">end</span>
</code></pre> <p>In other words, publish 10000 messages to the queue (in one process) and read those messages from the queue (in another process), noting how long it took to publish and read. Do this 25 times to get a min/max/average time for each of the different message sizes.</p> <p>I have attached the spreadsheet of the results which show: the larger the message, the longer it takes to publish and read from the queue. However, it also shows that Sparrow could handle the 64k messages while Rabbit/AMQP could not. Sparrow got slower to process those 10000 64k items from the queue, but it never failed as with Rabbit/AMQP. Ultimately, the deep dive was not about fixing a broken AMQP adapter.</p> <p>The Devil is in the Details</p> <p>One benefit of using Sparrow is that persistence is built into the server. If you take down Sparrow and there are messages on the queue, it will write those out to an SQLite3 database. Ultimately this lead me to look at the size of the field it was using for queue data which would need to be patched from its current 255 characters.</p> <p>Conclusion</p> <p>So, I&rsquo;ve now got a queue server that I feel comfortable setting up and using and that can probably handle the load of data we&rsquo;re going to throw at it come launch. The queue server/queues were integrated into PROJECT X in the context of the &ldquo;FEATURE X&rdquo; to prove its feasibility in addressing that feature in a future sprint.</p> <p>And one more thing &hellip;</p> <p>There are tests for the various bits that make up &ldquo;FEATURE X&rdquo;. I&rsquo;m most happy with the integration test which fires up a Sparrow server, fires up a foo, creates a bar, runs the aggregator, and checks to see that a baz was created for the account (oh and then cleaning up the queue server and the subscriber). 14 LOC, but there&rsquo;s a lot of code that it exercises behind the scenes. And yes, it passes :)</p> <hr> <p>So, there you go. Hopefully you have enough information to do your own Deep Dive.</p> <p>Ultimately for FEATURE X and FEATURE Y, Sparrow more than met our needs. Advances and changes to AMQP and its associated libraries have been made which I&rsquo;m sure make it a more than viable candidate. At the time however, with just getting the system to work for a day to prove out the Deep Dive, it just didn&rsquo;t meet our needs. Again, the point of this blog post is to talk about the Deep Dive in the larger context of its use in Scaling Ruby and Rails.</p> </div> </div> </div> <div class=blog-entry> <div class=blog__date> Dec 11 </div> <div class=blog__contents> <h2 class=blog__title> <a href="/blog/2009/12/11/thank-you-open-source/">Thank You Open Source</a> </h2> <div class=blog__author> By <strong>David Czarnecki</strong> </div> <div class=blog__body> <p>Here is a probably incomplete list of open source software/libraries/tools we use here regularly at Agora Games. Thanks!</p> <p><a href="http://rubyonrails.org/">Rails</a></p> <p><a href="http://www.ruby-lang.org/en/">Ruby</a></p> <p><a href="http://www.python.org/about/">Python</a></p> <p><a href="http://github.com/thoughtbot/factory_girl">Factory Girl</a></p> <p><a href="http://code.google.com/p/sparrow/">Sparrow</a></p> <p><a href="http://mocha.rubyforge.org/">Mocha</a></p> <p><a href="http://code.macournoyer.com/thin/">Thin</a></p> <p><a href="http://unicorn.bogomips.org/">Unicorn</a></p> <p><a href="http://spreecommerce.com/">SpreeCommerce</a></p> <p><a href="http://mmonit.com/monit/">Monit</a></p> <p><a href="http://nginx.net/">nginx</a></p> <p><a href="http://varnish.projects.linpro.no/">varnish</a></p> <p><a href="http://git-scm.com/">git</a></p> <p><a href="http://subversion.tigris.org/">Subversion</a></p> <p><a href="http://www.gnu.org/software/emacs/">emacs</a></p> <p><a href="http://mysql.com/">MySQL</a></p> <p><a href="http://memcached.org/">memcached</a></p> <p><a href="http://oss.oetiker.ch/rrdtool/">rrdtool</a></p> <p><a href="http://dennisbloete.de/projects/masquerade/">Masquerade</a></p> <p><a href="http://openidenabled.com/ruby-openid/">Ruby-OpenID</a></p> <p><a href="http://xml-simple.rubyforge.org/">XmlSimple</a></p> <p><a href="http://www.ubuntu.com/">Ubuntu</a></p> </div> </div> </div> <div class=blog-entry> <div class=blog__date> Nov 19 </div> <div class=blog__contents> <h2 class=blog__title> <a href="/blog/2009/11/19/large-files-with-nginx-gzip-and-ssl/">Large files with NGINX, GZip, and SSL</a> </h2> <div class=blog__author> By <strong>Jason LaPorte</strong> </div> <div class=blog__body> <p>I ran into an interesting issue today when deploying a crappy password change app I wrote as an exercise in rails. It turns out that by default, NGINX has a gzip buffer size of 4 * 4k/8k, with the bit size depending on what platform the service is running on.</p> <p>As a result,</p> <p>4 * 4k = 16384 bytes (16KB) 4 * 8k = 32768 (32KB)</p> <p>After gzip, when converted to be plain text, the amount of data returned to the browser nearly doubles (about 52KB in the case of larger). The default javascript library included by rails for AJAX (prototype.js) is 127k, which led me to find this limit.</p> <p>And so, getting to the point, the limit applied to the gzip buffer needs to be increased within NGINX&rsquo;s config files for each site that will use a file larger than these pre-set sizes. You can do so using the following:</p> <p><strong>gzip_buffers 16 8k</strong></p> <p>This will set the buffer size to 16 * 8k, or 128KB &ndash; the uncompressed size of the library, eliminating the issue.</p> <p>In the future if you find NGINX truncating large files for no apparent reason, this is likely why.</p> <p><strong>EDIT</strong> &ndash; In NGINX versions post 0.7.28, the default limit of gzip_buffers has been increased to 32 * 4 or 16 * 8 (rounding out to 128K, as noted above) depending on platform. It may be wise to double check any configs you may have to ensure you are not explicitly setting a lesser value, or upgrade NGINX if needed.</p> </div> </div> </div> <div class=blog-entry> <div class=blog__date> Oct 12 </div> <div class=blog__contents> <h2 class=blog__title> <a href="/blog/2009/10/12/spelunking-into-your-logs-with-splunk/">Spelunking into your logs with Splunk</a> </h2> <div class=blog__author> By <strong>Tim Jones</strong> </div> <div class=blog__body> <p>At Agora we&rsquo;re experimenting with Splunk as a error collection and reporting tool.  The idea is that all our services will spit out error information to syslog which will be picked up and indexed by Splunk.  Splunk will be configured to display info about recent errors, email summaries of those errors and generally be the starting point for discovering problems with our systems.  In our previous infrastructure error collection and reporting was handled on a per-project basis.  As we&rsquo;re now moving to a more service oriented approach that involves a small number of generic but highly configurable services deployed over a large number nodes we needed something different.  Splunk seems ideal for this.  It accepts a number of different data sources ranging from syslog to raw log files to inputs from random UDP and TCP ports so we can easily integrate with systems we&rsquo;ve written and, more importantly, those we haven&rsquo;t.  It also has the summary and reporting capabilities we were looking for so we can chart errors over time periods, dig for trends and see which services are acting up.</p> <p>The biggest problem I&rsquo;ve had so far while working with Splunk is the documenation.  There are a lot of options and the documentation for those options is spread out over a number of distinct manuals.  Some options are poorly documented or not at all and often it&rsquo;s not clear, even once you&rsquo;ve found the proper option, where/how the option should be used.  The following is an attempt to lay out some of those problems I ran into and what the solutions are so you don&rsquo;t have to go looking yourself.  This list will likely continue to grow over the coming weeks and months.</p> <ol> <li><strong>Extracting fields from search results</strong></li> </ol> <p>Splunk automatically extracts certain fields from your search results.  This is all well and good but what if you want to pull out your own values?  As an example we stick a field into our syslog output that indicates what service the log entry came from.  This would be extremely handy since we&rsquo;d then be able to filter out entries for a particular services, build charts with color coding based around the services and so on.  It turns out this is pretty easy.  Although this functionality is mentioned in the &lsquo;User Manual&rsquo; most of the ral documentation for the commands used can be found in the &lsquo;Search Manual&rsquo; (grrrr).  The portion in the User Manual can be found by search for &lsquo;Extract fields with search commands&rsquo;.  For the command information look for &lsquo;rex&rsquo; in the &lsquo;Search Commands&rsquo; section of the Search Reference.Anywho, the trick is in the &lsquo;rex&rsquo; command.  This can be chained onto your search request (something else that was not obvious) like many other Splunk commands:</p> <p>  sourcetype=&ldquo;syslog&rdquo; foo | rex field=_raw &ldquo;[0-9a-z]{2} err [(?<service>.*?)]&rdquo;  </p> <p>The rex command takes a regular expression and produces fields based on matches.  The field option specifies which of Splunk&rsquo;s default fields you want to match against (search in the Splunk manuals for &lsquo;Use default and internal fields&rsquo; for a list of all available fields).  The regex in this case matches two alphanumeric characters followed by the string &lsquo;err&rsquo; followed by a service name in brackets.  The ?<service> notation in parentheses indicates a match that should be saved in the &lsquo;service&rsquo; field.</p> <p>Once your search has been executed you should see that you can now filter on whatever fields you extracted, create charts with them, etc. 2. <strong>Extracting only those results that have a particular field</strong></p> <p>So you&rsquo;ve created a regex to extract certain fields from your result set but the results that don&rsquo;t match your regex are still in the result set.  How do you filter those out?  The solution is actually pretty simple:</p> <pre class="highlight plaintext"><code>&lt;your_original_search&gt; | rex &lt;your regex&gt; | search your_field="\*"
</code></pre> <p>Likewise you can find those that didn&rsquo;t match by negating the lookup:</p> <pre class="highlight plaintext"><code>&lt;your_original_search&gt; | rex &lt;your regex&gt; | search NOT your_field="*"
</code></pre> <ol> <li><strong>Changing indices for search</strong></li> </ol> <p>By default your searches will only hit the &lsquo;main&rsquo; index.  If you&rsquo;ve created your own index it won&rsquo;t be searched by default.  To use your index in a particular search just add it to the search string:</p> <pre class="highlight plaintext"><code>index=my_index foo NOT bar
</code></pre> <p>To add your index to the default list so you don&rsquo;t have to modify every search you&rsquo;ll need to modify your roles a bit.  Visit the Roles page in the Manager, select your role (probably user or admin if you haven&rsquo;t made any modifications here, and scroll down to the &lsquo;Default indexes&rsquo; list. 4. <strong>Displaying the body of a message in an event table</strong></p> <p>In our main dashboard we wanted to show a list of the 5 most recent errors.  This actually turned out to be more difficult than you might have expected.  The date, host, and a few other pieces of data showed up fine but for the life of me I couldn&rsquo;t figure out how to get the body of the log message to show up in the table.  There is a special field called _raw for each result but adding that to the table had no effect.  In the end my solution was to create a regexp against my search results that extracted a parameter called &lsquo;body&rsquo;.</p> <p>Search:</p> <pre class="highlight plaintext"><code>sourcetype="syslog" err | rex field=_raw "[0-9a-z]{2} err \[(?&lt;service&gt;.*?)\] (?&lt;body&gt;.*)"
</code></pre> <p>Event Table:</p> <pre class="highlight plaintext"><code>&lt;table&gt;
&lt;title&gt;Most recent service errors&lt;/title&gt;
&lt;searchName&gt;Service errors with body&lt;/searchName&gt;
&lt;option name="count"&gt;5&lt;/option&gt;
&lt;fields&gt;_time,host,body&lt;/fields&gt;
&lt;/table&gt;
</code></pre> <p>The events table:</p> <p><img alt=events width=801 height=247 src="/assets/images/uploads/2009/10/events-d43cf79e.png"/></p> <ol> <li><strong>Changing the default app</strong></li> </ol> <p>With a normal install the launcher is the default app.  This gets kind of annoying after a while.  To change it to your own app you can adjust the default<em>namespace option in $SPLUNK</em>HOME/etc/apps/user-prefs/local/user-prefx.conf.</p> <pre class="highlight plaintext"><code>default_namespace = my_app
</code></pre> <ol> <li><strong>Email alerts</strong></li> </ol> <p>Email alerts are built around scheduled searches.  When saving or editing a search you&rsquo;re given the option to provide a schedule for it.  Change this option so that the search is run on some interval and additional options will appear including one to send an email alert.  Additionally you can modify the search to only include a certain time range.  These features are very handy when used in combination.  Schedule your search to run every 30 minutes and adjust the start time to -30m and you&rsquo;ll get alerts about all errors that occurred during that time.</p> <p>Mail settings themselves can be found in Manager -&gt; Email alert settings. 7. <strong>Stacked time-based charts</strong></p> <p>Took me a while to sort out this one.  The first thing you need to do is group your data into larger time periods.  If you have one column for each second your graph is going to be pretty useless.  Instead you should consolidate your data into large groups such as one per minute or one per hour.  I&rsquo;ve found that dividing your time range by roughly 30 gives the best graphs.  To actually perform this grouping you need to add the &lsquo;span&rsquo; option to your search:</p> <pre class="highlight plaintext"><code>sourcetype="syslog" foo NOT bar | timechart span=1h count
</code></pre> <p>This will produce a count of all the items containing foo and not bar for syslog in intervals of one hour.</p> <p>Next you need to stack the resulting groups.  Annoyingly this is done at the view layer.  In my case I was adding it to my dashboard.  The relevant lines looked similar to the following:</p> <pre class="highlight plaintext"><code>&lt;chart&gt;
&lt;searchName&gt;Service errors in the last 24 hours&lt;/searchName&gt;
&lt;title&gt;Service errors in the last 24 hours&lt;/title&gt;
&lt;option name="charting.chart"&gt;column&lt;/option&gt;
&lt;option name="charting.chart.stackMode"&gt;stacked&lt;/option&gt;
&lt;/chart&gt;
</code></pre> <p>There is a reference for all these options in the Splunk docs.  Search for &lsquo;Custom charting configurations&rsquo;.</p> <p>The end result looks something like this:</p> <p><img alt=errors width=804 height=245 src="/assets/images/uploads/2009/10/errors-99369b2b.png"/></p> <ol> <li><strong>Edit everything manually</strong></li> </ol> <p>The Splunk Manager interface is rather clunky (not entirely the developer&rsquo;s fault, there are a lot of interdependent options) so after a while you&rsquo;ll likely get sick of it.  That&rsquo;s perfectly fine.  All the options are written out to config files per app.  All your changes are written out to $SPLUNK<em>HOME/etc/apps/&lt;your</em>app&gt;/local and override those options in $SPLUNK<em>HOME/etc/apps/&lt;your</em>app&gt;/default.  The default directory can be used as a handy reference for available options as well.  Note that some system wide options such as indices and roles are written out to $SPLUNK_HOME/etc/system/local. 9. <strong>Don&rsquo;t delete the &lsquo;user&rsquo; role</strong></p> <p>If you do you&rsquo;ll be sad as it breaks everything.  I&rsquo;d attempted to remove the role and replace it with our own modified version.  The result was that every page I visited gave me a &ldquo;Client not authorized&rdquo; error.  To resolve the problem delete the &lsquo;disabled = 1&rsquo; line from $SPLUNK_HOME/etc/system/local/authorize.conf. 10. <strong>Adding output to syslog(-ng)</strong></p> <p>As mentioned previously our Splunk setup is largely based on syslog but because we want to have raw syslog files in addition to having them indexed by Splunk we allow syslog to write the logs to disk and then have Splunk watch the created files.  Some information such as facility and log level get lost during this process with most default syslog configurations.  To resolve this we did a little bit of reconfiguring to our syslog installs.First, it&rsquo;s important to note that we actually use syslog-ng rather than vanilla syslog.  Syslog-ng has some handy options for templating output as of 1.5.3.  For each destination you can specify a template function:</p> <pre class="highlight plaintext"><code>destination df_syslog { file("/var/log/syslog" template("$FULLDATE $FULLHOST $TAG $LEVEL $MESSAGE\n") template_escape(no)); };
</code></pre> <p>FULLDATE includes the year in the timestamp.  FULLHOST provides the hostname.  TAG is a hex encoding of the facility and level.  $LEVEL is a text representation of the level.  $MESSAGE is obviously just the message.  The template_escape(no) directive says that quotes should not be escaped.  Also note the newline at the end of the template.  Without it your output will be rather unreadable.</p> <p>And for reference the default appears to be similar to:</p> <pre class="highlight plaintext"><code>"$DATE $FULLHOST $MESSAGE\n" template_escape(no)
</code></pre> </div> </div> </div> <div class=blog-entry> <div class=blog__date> Oct 7 </div> <div class=blog__contents> <h2 class=blog__title> <a href="/blog/2009/10/07/integrating-lighthouse-and-instant-messenger-in-ruby/">Integrating Lighthouse and Instant Messenger in Ruby</a> </h2> <div class=blog__author> By <strong>David Czarnecki</strong> </div> <div class=blog__body> <p>The <a href="http://lighthouseapp.com/api/introduction">Introduction to the Lighthouse API</a> mentions something you might do with the Lighthouse API is &ldquo;Accessing and creating tickets through your Instant Messenger client.&rdquo;. How easy is it to do this? Surprisingly easy.</p> <p>You will need to download and install the <a href="http://github.com/Caged/lighthouse-api">Lighthouse API</a> gem and the <a href="http://net-toc.rubyforge.org/doc/classes/Net/TOC.html">Net::TOC</a> gem.</p> <p>Run this in an irb session.</p> <pre class="highlight ruby"><code>
 <span class="nb">require</span> <span class="s1">'net/toc'</span>
 <span class="nb">require</span> <span class="s1">'lighthouse'</span>
 <span class="nb">require</span> <span class="s1">'sanitize'</span>
 <span class="kp">include</span> <span class="no">Lighthouse</span>

 <span class="no">Lighthouse</span><span class="p">.</span><span class="nf">account</span> <span class="o">=</span> <span class="s1">'shaft'</span>
 <span class="no">Lighthouse</span><span class="p">.</span><span class="nf">token</span> <span class="o">=</span> <span class="s1">'hesonebadmotherfushutyourmouth'</span>

 <span class="no">Net</span><span class="o">::</span><span class="no">TOC</span><span class="p">.</span><span class="nf">new</span><span class="p">(</span><span class="s2">"someaimaccount"</span><span class="p">,</span> <span class="s2">"someaimpassword"</span><span class="p">)</span> <span class="k">do</span> <span class="o">|</span><span class="n">msg</span><span class="p">,</span> <span class="n">buddy</span><span class="o">|</span>
 <span class="n">project</span> <span class="o">=</span> <span class="no">Project</span><span class="p">.</span><span class="nf">find</span><span class="p">(</span><span class="no">Sanitize</span><span class="p">.</span><span class="nf">clean</span><span class="p">(</span><span class="n">msg</span><span class="p">).</span><span class="nf">to_i</span><span class="p">)</span>
 <span class="n">buddy</span><span class="p">.</span><span class="nf">send_im</span><span class="p">(</span><span class="s2">"Here is some information about your project: </span><span class="si">#{</span><span class="n">project</span><span class="p">.</span><span class="nf">name</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
 <span class="k">end</span>

</code></pre> <p>You should then be able to add &lsquo;someaimaccount&rsquo; to your AIM buddy list and send a project ID and have it return the project name.</p> <p>And boom goes the dynamite!</p> <p>You&rsquo;ll of course need to change the Lighthouse account and token as appropriate (or use username and password for logging in). msg is a little weird and although it&rsquo;s a string, it&rsquo;s HTML, so you need to strip out any tags before doing anything. And of course you&rsquo;d want to add in some way of parsing the input from the user into some DSL (Domain Specific Language) for interacting with your fancy new Lighthouse AIM bot.</p> <p>Happy hacking!</p> </div> </div> </div> <div class=blog-entry> <div class=blog__date> Oct 1 </div> <div class=blog__contents> <h2 class=blog__title> <a href="/blog/2009/10/01/mocking-http-request-and-response-with-python-and-mox/">Mocking HTTP request and response with Python and Mox</a> </h2> <div class=blog__author> By <strong>Aaron Westendorf</strong> </div> <div class=blog__body> <p>I recently started integrating with some web services in Python and wanted to be able to test all the requests and responses with valid and invalid data. However, I need to be able to do this without actually hitting the web service when testing. And of course I don&rsquo;t want to change my web service code to conditionally do things if running in a test environment. Enter mocking and Mox.</p> <p>One of our engineers, Tim, has written an excellent post on his adventures as a Ruby programmer getting up to speed on <a href="http://blog.agoragames.com/2009/02/23/python-is-mocking-me-a-ruby-programmers-adventures-with-pythonmox/">testing and mocking in Python using Mox</a>. You should read it.</p> <p>Back to my issue with mocking the HTTP request and response.</p> <p>Here is what I came up with. I first created a MockResponse class that adds a read() method to the string class.</p> <pre class="highlight python"><code>
<span class="k">class</span> <span class="nc">MockResponse</span><span class="p">(</span><span class="nb">str</span><span class="p">):</span>
  <span class="s">'''
  Mock response class with a method called read which will be used similar to the response from an HTTP request to a URL
  '''</span>
  <span class="k">def</span> <span class="nf">read</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span>
</code></pre> <p>And here is a test in which I mock out the request and response for the urllib2.OpenerDirector.open method. I don&rsquo;t so much care what the request string is passed to the open call, so I use IgnoreArg(). And I return the XML that would be returned by the actual web service to indicate the username and/or password were incorrect.</p> <pre class="highlight python"><code><span class="k">def</span> <span class="nf">test_logging_in_to_network_with_bad_username_and_password</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">my_network_service</span> <span class="o">=</span> <span class="n">MyNetworkService</span><span class="p">(</span><span class="s">'foo'</span><span class="p">,</span> <span class="s">'bar'</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mock</span><span class="p">(</span><span class="n">urllib2</span><span class="o">.</span><span class="n">OpenerDirector</span><span class="p">,</span> <span class="s">'open'</span><span class="p">)</span>
    <span class="n">urllib2</span><span class="o">.</span><span class="n">OpenerDirector</span><span class="o">.</span><span class="nb">open</span><span class="p">(</span><span class="n">mox</span><span class="o">.</span><span class="n">IgnoreArg</span><span class="p">())</span><span class="o">.</span><span class="n">AndReturn</span><span class="p">(</span><span class="n">MockResponse</span><span class="p">(</span><span class="s">'''30000ACCT_LOGIN_FAILED7'''</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">replay_all</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">assertEqual</span><span class="p">(</span><span class="bp">False</span><span class="p">,</span> <span class="n">my_network_service</span><span class="o">.</span><span class="n">login</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mox</span><span class="o">.</span><span class="n">UnsetStubs</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mox</span><span class="o">.</span><span class="n">VerifyAll</span><span class="p">()</span>
</code></pre> <p>If there&rsquo;s a better way, I&rsquo;d love to hear your suggestions.</p> </div> </div> </div> <div class=blog-entry> <div class=blog__date> Sep 4 </div> <div class=blog__contents> <h2 class=blog__title> <a href="/blog/2009/09/04/go-go-section8/">Go go Section8!</a> </h2> <div class=blog__author> By <strong>Brian Corrigan</strong> </div> <div class=blog__body> <p>We just (as in 10 minutes ago!) launched the statistics portal for <a href="http://www.joinsection8.com/">Section8</a>, a first person shooter by <a href="http://www.timegate.com/">Timegate</a> and <a href="http://www.southpeakgames.com/region.php">SouthPeak Games</a>.  Go check it out at <a href="http://s8stats.timegate.com">http://s8stats.timegate.com</a> and join our clan while we still have a few spots open!</p> <p>If you haven&rsquo;t yet played <a href="http://www.joinsection8.com/">Section8,</a> you owe it to yourself to download the demo on XBOX Live or hit up GameStop for a copy.  The single player action is fun and the multi-player totally rocks.</p> <p>Congratulations to both the team at <a href="http://www.timegate.com/">Timegate</a> our internal project team including:</p> <ul> <li>Producer - Steven Flenory</li> <li>Associate Producer - Mike Jodon</li> <li>Lead Engineer - Eric Torrey</li> <li>Contributing Engineer - Ola Mork</li> <li>Interface/Frontend Engineer - Josh Childs</li> <li>Lead Interface Design - Christian Arca</li> <li>Interface Design - Elliott Haase</li> <li>QA - Joe Falzano &amp; Devon Smith</li> <li>Systems Administrator - Jason Laporte</li> <li>Visual Design - <a href="http://www.id29.com/">ID29</a> (Special shout out to our buddy Bryan Kahrs!)</li> </ul> <p>Nice job all around folks.  Now get ready for the next round of features!</p> </div> </div> </div> <div class=blog-entry> <div class=blog__date> Aug 18 </div> <div class=blog__contents> <h2 class=blog__title> <a href="/blog/2009/08/18/major-league-gaming-agora-games-crazy-delicious/">Major League Gaming + Agora Games = Crazy Delicious</a> </h2> <div class=blog__author> By <strong>David Czarnecki</strong> </div> <div class=blog__body> <p><a href="http://www.mlgpro.com/content/page/288410/Major-League-Gaming-Acquires-Agora-Games">Major League Gaming acquires Agora Games</a></p> <p>I&rsquo;m just going to parrot the MLG news post here.</p> <blockquote> <h3>MAJOR LEAGUE GAMING ACQUIRES AGORA GAMES</h3> <p><em>Deal brings online, multi-platform development expertise to fast-growing competitive gaming property</em></p> </blockquote> <p><strong>NEW YORK CITY—AUGUST 18, 2009—</strong>Major League Gaming today announced that it has acquired Troy, NY-based Agora Games. Known for both its technical expertise and elegant product development, Agora has built some of the leading video game community applications in the industry. Together, Agora and MLG will work both to enhance MLG’s online offerings, as well as to expand the services that both companies currently offer to the game publishing community.</p> <p>“Cross-platform video game competition is what MLG is all about,” said Matthew Bromberg, president and CEO of Major League Gaming. “We already operate the largest online competitive gaming property in the world. Agora is the leading developer of multi-player communities in the world. Coming together with Agora allows us to double-down on our biggest strength.”</p> <p>Over the last four years, Agora has developed some of gaming’s highest profile, most ambitious community websites for titles including Guitar Hero, Transformers, Call of Duty World at War, and Dance Dance Revolution. Their technology currently tracks game play statistics for over 25 million players around the world. Founder Michael DelPrete will remain as president of the wholly-owned subsidiary. Agora will continue to operate out of its Troy, NY office. Terms of the deal were not disclosed.</p> <p>“MLG has shown the world that competitive video gaming is both a great live sports experience and can be the basis for a thriving online business,” said Michael DelPrete, founder of Agora Games. “We share a vision of the marketplace, and we’re confident the combination will better serve our existing customers and open up new opportunities to expand our offerings.”</p> <p>The acquisition presents significant opportunities for game publishers. Agora has become the go-to technology developer for handheld and web-based extensions of video game experiences. Major League Gaming has proven its ability to build massive audiences around exciting new competitive social experiences. Together, Agora and MLG will partner more deeply with publishers and developers looking for deeper engagement, more ever-green experiences, and greater unit volume.</p> <p><strong>ABOUT MAJOR LEAGUE GAMING</strong> Major League Gaming is the largest professional video game league in the world. MLG is the dominant media property exclusively targeting the approximately 40 million consumers in North America who have a passion for playing video games as a competitive social activity, while giving sponsoring brands access to this highly influential demographic. We represent the best professional gamers and give millions of aspiring players around the world an opportunity to compete, improve their skills, and socialize through our thriving online community and live Pro Circuit competitions.</p> <blockquote> </blockquote> </div> </div> </div> <div class=blog-entry> <div class=blog__date> Aug 13 </div> <div class=blog__contents> <h2 class=blog__title> <a href="/blog/2009/08/13/more-transformers-please/">More Transformers Please!</a> </h2> <div class=blog__author> By <strong>Christian Arca</strong> </div> <div class=blog__body> <p>Once again, our work for Transformers: Revenge of the Fallen on the Nintendo DS has been &lsquo;called out&rsquo;. This time it&rsquo;s Wii DS UK from - you guessed it - across the pond. They call Battle For Eath a, &ldquo;bright light.&rdquo; Here&rsquo;s their bit about Battle For Earth:</p> <blockquote> <p><em>While there’s the usual ‘link-up with your friends and kill them’-style deathmatch, allowing players who own either version of the game to pound on each other with the named characters from the story or their character from the main game, there’s also a special mode called Battle For Earth, which lets players duke it out for fame and glory, a list of the best players available on the official website.  The missions are more or less the same as the ones available in the main storyline, so it’s not ‘true’ DLC, but it’s certainly a step in the right direction for any DS owners looking at their console-owning comrades in jealousy.</em> _For the full review be sure to visit <a href="http://www.wiids.co.uk/2009/08/11/transformers-revenge-of-the-fallen-decepticons-ds-review/">http://www.wiids.co.uk/2009/08/11/transformers-revenge-of-the-fallen-decepticons-ds-review/</a>. _</p> </blockquote> </div> </div> </div> </div> <div class=blog-pagination> <ul class=inline-list> <li> <a href="/blog/page/25/">« Older entries </a></li> <li>Page 24 of 28</li> <li> <a href="/blog/page/23/">Newer entries » </a></li> </ul> </div> </div> <div class='columns large-3'> <div class=blog-archives-sidebar> <h2>Blog archives</h2> <h3> <a href="/blog/2015/">2015</a> </h3> <ul> <li> <a href="/blog/2015/10/">October 2015</a> </li> <li> <a href="/blog/2015/03/">March 2015</a> </li> <li> <a href="/blog/2015/01/">January 2015</a> </li> </ul> <h3> <a href="/blog/2014/">2014</a> </h3> <ul> <li> <a href="/blog/2014/12/">December 2014</a> </li> <li> <a href="/blog/2014/11/">November 2014</a> </li> <li> <a href="/blog/2014/10/">October 2014</a> </li> <li> <a href="/blog/2014/08/">August 2014</a> </li> <li> <a href="/blog/2014/07/">July 2014</a> </li> <li> <a href="/blog/2014/06/">June 2014</a> </li> <li> <a href="/blog/2014/04/">April 2014</a> </li> <li> <a href="/blog/2014/03/">March 2014</a> </li> <li> <a href="/blog/2014/02/">February 2014</a> </li> <li> <a href="/blog/2014/01/">January 2014</a> </li> </ul> <h3> <a href="/blog/2013/">2013</a> </h3> <ul> <li> <a href="/blog/2013/11/">November 2013</a> </li> <li> <a href="/blog/2013/10/">October 2013</a> </li> <li> <a href="/blog/2013/09/">September 2013</a> </li> <li> <a href="/blog/2013/08/">August 2013</a> </li> <li> <a href="/blog/2013/07/">July 2013</a> </li> <li> <a href="/blog/2013/06/">June 2013</a> </li> <li> <a href="/blog/2013/05/">May 2013</a> </li> <li> <a href="/blog/2013/04/">April 2013</a> </li> <li> <a href="/blog/2013/03/">March 2013</a> </li> <li> <a href="/blog/2013/02/">February 2013</a> </li> <li> <a href="/blog/2013/01/">January 2013</a> </li> </ul> <h3> <a href="/blog/2012/">2012</a> </h3> <ul> <li> <a href="/blog/2012/12/">December 2012</a> </li> <li> <a href="/blog/2012/11/">November 2012</a> </li> <li> <a href="/blog/2012/10/">October 2012</a> </li> <li> <a href="/blog/2012/09/">September 2012</a> </li> <li> <a href="/blog/2012/08/">August 2012</a> </li> <li> <a href="/blog/2012/07/">July 2012</a> </li> <li> <a href="/blog/2012/06/">June 2012</a> </li> <li> <a href="/blog/2012/05/">May 2012</a> </li> <li> <a href="/blog/2012/04/">April 2012</a> </li> <li> <a href="/blog/2012/03/">March 2012</a> </li> <li> <a href="/blog/2012/02/">February 2012</a> </li> <li> <a href="/blog/2012/01/">January 2012</a> </li> </ul> <h3> <a href="/blog/2011/">2011</a> </h3> <ul> <li> <a href="/blog/2011/10/">October 2011</a> </li> <li> <a href="/blog/2011/09/">September 2011</a> </li> <li> <a href="/blog/2011/08/">August 2011</a> </li> <li> <a href="/blog/2011/07/">July 2011</a> </li> <li> <a href="/blog/2011/06/">June 2011</a> </li> <li> <a href="/blog/2011/05/">May 2011</a> </li> <li> <a href="/blog/2011/04/">April 2011</a> </li> <li> <a href="/blog/2011/03/">March 2011</a> </li> <li> <a href="/blog/2011/02/">February 2011</a> </li> <li> <a href="/blog/2011/01/">January 2011</a> </li> </ul> <h3> <a href="/blog/2010/">2010</a> </h3> <ul> <li> <a href="/blog/2010/12/">December 2010</a> </li> <li> <a href="/blog/2010/11/">November 2010</a> </li> <li> <a href="/blog/2010/10/">October 2010</a> </li> <li> <a href="/blog/2010/09/">September 2010</a> </li> <li> <a href="/blog/2010/08/">August 2010</a> </li> <li> <a href="/blog/2010/07/">July 2010</a> </li> <li> <a href="/blog/2010/06/">June 2010</a> </li> <li> <a href="/blog/2010/05/">May 2010</a> </li> <li> <a href="/blog/2010/04/">April 2010</a> </li> <li> <a href="/blog/2010/03/">March 2010</a> </li> <li> <a href="/blog/2010/02/">February 2010</a> </li> <li> <a href="/blog/2010/01/">January 2010</a> </li> </ul> <h3> <a href="/blog/2009/">2009</a> </h3> <ul> <li> <a href="/blog/2009/12/">December 2009</a> </li> <li> <a href="/blog/2009/11/">November 2009</a> </li> <li> <a href="/blog/2009/10/">October 2009</a> </li> <li> <a href="/blog/2009/09/">September 2009</a> </li> <li> <a href="/blog/2009/08/">August 2009</a> </li> <li> <a href="/blog/2009/07/">July 2009</a> </li> <li> <a href="/blog/2009/06/">June 2009</a> </li> <li> <a href="/blog/2009/05/">May 2009</a> </li> <li> <a href="/blog/2009/04/">April 2009</a> </li> <li> <a href="/blog/2009/03/">March 2009</a> </li> <li> <a href="/blog/2009/02/">February 2009</a> </li> <li> <a href="/blog/2009/01/">January 2009</a> </li> </ul> <h3> <a href="/blog/2008/">2008</a> </h3> <ul> <li> <a href="/blog/2008/11/">November 2008</a> </li> <li> <a href="/blog/2008/10/">October 2008</a> </li> <li> <a href="/blog/2008/09/">September 2008</a> </li> <li> <a href="/blog/2008/08/">August 2008</a> </li> </ul> </div> </div> </div> <script src="/assets/javascripts/app-8d34dc05.js" async=true></script> </body> </html>