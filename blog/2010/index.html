<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible"><meta content="width=device-width" name="viewport"><title>Brain Matters</title><link href="/assets/images/favicon.ico" rel="shortcut icon"><link href="/assets/stylesheets/all-f38fbbc7.css" media="all" rel="stylesheet" type="text/css" /><!--[if lt IE 9]><script src="/assets/javascripts/vendor/html5shiv-8b3747c5.js" type="text/javascript"></script><![endif]--></head><body><div class="outer-wrap"><div class="inner-wrap"><div class="wrap"><header class="clearfix" id="page"><a href="/"><img alt="Agora Games" id="logo" src="/assets/images/agora-games-logo-be83adf8.png"></a><nav><ul><li><a href="https://hydra.agoragames.com/">Products</a></li><li><a href="/portfolio/">Customers</a></li><li><a href="/us/">Team</a></li><li><a href="/community/">Community</a></li><li><a href="/work-at-agora/">Jobs</a></li><li><a href="/blog/">Blog</a></li></ul></nav></header></div><div class="wrap"><article class="clearfix"><header><h1>2010</h1></header><section id="blog-entries"><div class="blog-entry"><div class="date-comments"><div class="date">Dec 10</div></div><div class="blog-content"><h2><a href="/blog/2010/12/10/captcha-failed-or-how-i-patched-ruby-recaptcha-in-5-minutes-for-success/">CAPTCHA failed or How I Patched ruby-recaptcha In 5 Minutes For Success</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>We are using the <a href="http://bitbucket.org/mml/ruby-recaptcha/wiki/Home">ruby-recaptcha</a> library here at Agora Games. I got a bug from our QA department that they wanted the CAPTCHA failure message to change from 'Captcha failed.' to 'CAPTCHA failed.'.</p>

<p>I love that the Ruby and Rails community is so test-focused. I looked at the ruby-recaptcha issue tracker and there was already a patch for adding in customizable message support. However, with the patch, none of the tests passed. It was well within the library author's rights to give that patch the middle finger.</p>

<p>So, what did I do? I applied the patch to my local copy of the ruby-repatcha library, fixed the tests, and <a href="http://bitbucket.org/mml/ruby-recaptcha/issue/2/make-the-error-message-customizable#comment-313094">submitted an updated patch</a>.</p>

<p>Success.</p>

<p>You can find more hilarity over on my Twitter account, <a href="http://twitter.com/czarneckid">CzarneckiD</a>.</p>

<p><img alt="" title="happy-ruby" src="http://static.rubyrags.com/pictures/1/ruby_makes_me_happy.png" /></p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Dec 9</div></div><div class="blog-content"><h2><a href="/blog/2010/12/09/hello-there/">Hello there...</a></h2><div class="blog-author">By <strong>Steven Davidovitz</strong></div><div class="blog-body"><p>I'm Steven. I hail from the suburbs of Boston and I'm currently a 3rd year student at the Rochester Institute of Technology where we are required to do a minimum of 12 months of full time co-op before graduation. Agora Games is my 3rd and final co-op experience and I'm very excited to be working here!</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Dec 9</div></div><div class="blog-content"><h2><a href="/blog/2010/12/09/lightweight-concurrency-with-ruby-and-eventmachine/">Lightweight concurrency with Ruby and Eventmachine</a></h2><div class="blog-author">By <strong>Steven Davidovitz</strong></div><div class="blog-body"><p><a title="Eventmachine" href="http://rubyeventmachine.com">Eventmachine</a> describes itself as a "fast, simple event-processing library for Ruby programs." Included in it is a module called Deferrable that allows easy and lightweight concurrency. Deferrable makes it simple to spawn a blocking or long running operation, push it to the background, and on completion execute any number of code blocks (callbacks).</p>

<p>Below, I've written a sample application that uses the Deferrable class and Eventmachine's event loop to parallelize HTTP API calls to <a title="whoismyrepresentative.com" href="http://whoismyrepresentative.com">whoismyrepresentative.com</a>.</p>

<p>{% gist 734988 %}</p>

<p>As each request is created it placed in a pool with all other requests which are then spawned and executed after a call to Request.run. As the GET calls come back they are checked for an error message and based upon that the appropriate callbacks attached at the creation of the request are called. In this case, if the call succeeds each representative for that zip code is printed out along with a phone number. If it fails, the error message is printed. As the output below shows, the calls are done completely in parallel and immediately after they return the callbacks are executed.</p>

<p>{% gist 734989 %}</p>

<p>As the number of requests increases, so does the performance benefit of using this model. Example timings for 25 requests done serially and in parallel are below.</p>

<p>{% gist 735018 %}</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Dec 2</div></div><div class="blog-content"><h2><a href="/blog/2010/12/02/my-freedom-patch-gem-constant-redefinition/">My "Freedom Patch" Gem: constant-redefinition</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>The <a href="https://rubygems.org/gems/constant-redefinition">constant-redefinition gem</a> allows you to define constants if not defined on an object and redefine constants without warning.</p>

<p>Are you still with me? Good.</p>

<p>The code "credit" for this gem comes from the Stack Overflow post, <a href="http://stackoverflow.com/questions/3375360/how-to-redefine-a-ruby-constant-without-warning">"How to redefine a Ruby constant without warning?"</a>. It just so happens that I was working on a project today where our test suite was testing a large number of iterations to write out data. I wanted to redefine the number of iterations in test (based on a constant in the model) to respect the spirit of the test, but not do as many iterations in test. I googled, found that post, and it seemed like a neatly packageable item that would be useful to other developers.</p>

<p>So, I created the <a href="https://rubygems.org/gems/constant-redefinition">constant-redefinition gem</a>. You can also check out the <a href="https://github.com/czarneckid/constant-redefinition">GitHub constant-redefinition project</a>. My contribution was merely packaging it up as a gem, formalizing the tests, and making the method names longer (sue me, I prefer readability).</p>

<p>The project page has a good overview of using the two methods, but I'll reproduce it here.</p>

<p>{% gist 726069 %}</p>

<p>You may know "freedom patch" by its other names, "monkey patch" or "duck punch".</p>

<p>You can find more hilarity over on my Twitter account, <a href="http://twitter.com/czarneckid">CzarneckiD</a>.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Nov 30</div></div><div class="blog-content"><h2><a href="/blog/2010/11/30/to-version-or-not-to-version-your-gems-in-gemfiles/">To Version or Not To Version Your Gems in Gemfiles</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>I don't like moving targets. I'm a software developer, not a sharpshooter. So why don't more people version all of their gems in a Gemfile?</p>

<p>Here is a sample Gemfile for a Rails 3 application I was looking at yesterday.</p>

<p>{% gist 721842 %}</p>

<p>The gems for Rails and thin have been versioned. Why aren't the gems for will_paginate, nokogiri, and haml versioned? I consider un-versioned gems moving targets. Why? You're going to get the latest version of a gem. The developer doesn't know (or necessarily care) you depend on XXX functionality in version 1.0.23 of their gem. And so what if in version 2.0.0 of their gem, they make incompatible changes that break your application? I consider versioned gems a virtual "stake in the ground". To the best of my abilities, with rigorous testing of course, I know that given these specific versions of gems, my application performs as expected.</p>

<p>What's your opinion?</p>

<p><strong>UPDATE:</strong></p>

<p>Good point from my co-worker, Blake, who says that bundle will install the lastest version of a gem and then lock the version in your Gemfile.lock file on the first go-round. It could still be an issue if you do a "bundle update" locally or in your deployment process.</p>

<p>You can find more hilarity over on my Twitter account, <a href="http://twitter.com/czarneckid">CzarneckiD</a>.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Nov 30</div></div><div class="blog-content"><h2><a href="/blog/2010/11/30/a-better-way-to-avoid-a-project-named-server/">A Better Way to Avoid a Project Named Server</a></h2><div class="blog-author">By <strong>Blake Taylor</strong></div><div class="blog-body"><p>Yesterday I posted about how I avoided creating the annoying rails server projects when accidently running rails server under a rails 2 application. I wanted to follow up with a much more concise script that accomplishes the same ends through different means. Using this script requires no changes to how you start the development server and, even cooler perhaps, allows you to start the rails 2 server as if you were in a rails 3 project. Shout out goes to Intern Mike for the assist.</p>

<p>{% gist 722473 %}</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Nov 29</div></div><div class="blog-content"><h2><a href="/blog/2010/11/29/moving-to-rails-3-pain-point-rails-server/">Moving to Rails 3 Pain Point: rails server</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p><strong>Update:</strong> <em>I have posted a <a href="http://blog.agoragames.com/2010/11/30/a-better-way-to-avoid-a-project-named-server/">better solution</a>!</em></p>

<p>Working with rails 2 and 3 projects back and forth, day to day has been pretty painless thanks to <a href="http://rvm.beginrescueend.com/">rvm</a> and <a href="http://rvm.beginrescueend.com/workflow/rvmrc/">.rvmrc files</a>. That is with the exception of accidentally running <code>rails server</code> on a rails 2 project. I do this all the time and it results in generating a new rails project called server rather then starting the rails server, my actual intention. It's almost as frustrating when running <code>script/server</code> on a rails 3 project but at least it doesn't spit out a bunch of useless files. Incidentally, all of the built in rails command (i.e. generate, console, …) set the same trap. To avoid falling prey, I have created a bunch of shell functions which I would like to share with everyone in case they would like to be privy as well.</p>

<p>The shell code is included in the gist below. I load these functions into my .bashrc file (actually my .zshrc file). Once they are are available just get in the habit of running <code>rails-server</code> or <code>rails-generate</code> or <code>rails-whatever</code> and the correct command will always be issued. Also, if anyone knows a better solution, do share!</p>

<p>As one final note, I run <code>rails-server</code> so often that I have is aliased to <code>s</code> . If you would like to do the same add <code>alias s=rails-server</code> to your .bashrc file.</p>

<p>{% gist  720619 %}</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Nov 24</div></div><div class="blog-content"><h2><a href="/blog/2010/11/24/interactive-git-stash-for-stashing-single-or-multiple-files/">Interactive Git Stash For Stashing Single or Multiple Files</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p><strong>TL;DR</strong> git stash save –patch</p>

<p>From the git docs, "With –patch, you can interactively select hunks from in the diff between HEAD and the working tree to be stashed."</p>

<p>This past week, I came across a situation where I wanted to stash a couple of working files in a git repository, pull in some changes, and then apply the stash. However, I couldn't immediately see the forest for the trees or some other stupid metaphor. Basically it was just a case where I had to RTFM for git stash. In the gist below, I go through a simple example of stashing 2 out of 3 files, making some changes to the repository, and then applying the changes of the 2 stashed files.</p>

<p>{% gist 714660 %}</p>

<p>I hope you found this example useful. I know that it's some git-fu I'll be using more often.</p>

<p>You can find more hilarity over on my Twitter account, <a href="http://twitter.com/czarneckid">CzarneckiD</a>.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Nov 23</div></div><div class="blog-content"><h2><a href="/blog/2010/11/23/haloreachapi-new/">Halo::Reach::API.new</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>If you've ever wanted to access your Halo:Reach statistics from Ruby, you can now using the <a href="https://rubygems.org/gems/halo-reach-api">Halo:Reach Ruby gem</a>.</p>

<p>The API methods should be pretty self-explanatory and you can check out the <a href="http://rubydoc.info/gems/halo-reach-api/1.0.0/frames">gem's RDoc online</a> or look at the <a href="http://www.haloreachapi.net/wiki/Available_methods">unofficial API method documentation</a> for more information. Maybe the one caveat to getting involved in the project or using the API in general is that you need a Bungie Pro account to generate an API key. This will cost you 750 MS points per year. An 800 MS point pack will cost you $10.</p>

<p>You can also get involved in the development of the API over on the <a href="https://github.com/agoragames/halo-reach-api">Halo:Reach Ruby API GitHub project</a>.</p>

<p>You can find more hilarity over on my Twitter account, <a href="http://twitter.com/czarneckid">CzarneckiD</a>.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Nov 23</div></div><div class="blog-content"><h2><a href="/blog/2010/11/23/agora-games-major-league-gaming-participate-in-the-webs-first-multicast-transmission/">Agora Games & Major League Gaming participate in the web's first multicast transmission</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>When you send a unicast message it gets routed within a network to a single destination.  Unlike unicast messages, multicast messages get delivered to every node within a network.  If not properly controlled however you can experience routing loops which, like feedback between a microphone and a speaker, cause what networking techs call "multicast storms".  Because of this many corporate networks block multicast messages from ever leaving a single broadcast domain.  For the same reason, multicast messages are blocked by all Internet Service Providers at the network's edge.</p>

<p>Apparently it was just a matter of time until someone with a big enough backbone started letting them through.</p>

<p>On November 12, 2010 during Major League Gaming's National Finals in Dallas we working with AT&amp;T and Octoshape to deliver the first open-web multicast video stream.  Who doesn't love the bleeding edge?</p>

<p>Check out the details here:</p>

<p><a href="http://www.attinnovationspace.com/2010/11/23/first-ever-open-web-multicast-event/#more-523">http://www.attinnovationspace.com/2010/11/23/first-ever-open-web-multicast-event/#more-523</a></p>

<p>More musings can be found on my Twitter account, <a href="http://www.twitter.com/genexp">genexp</a></p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Nov 22</div></div><div class="blog-content"><h2><a href="/blog/2010/11/22/going-all-the-way-with-factory_girl-and-rails3-generators/">Going All The Way With factory_girl and rails3-generators</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>I responded to a few tweets from <a href="http://twitter.com/barrettclark">Barrett Clark</a> about <a href="https://github.com/thoughtbot/factory_girl">factory_girl</a> noting that you can get a lot more functionality out of factory_girl than just replacing fixtures. However, let's keep things simple to start and just replace fixtures with factory_girl in a simple Rails 3 application.</p>

<p>I want to replace fixtures in my new Rails 3 projects with factories. One of the best ways of doing that is to start a new Rails 3 project. Let's do that.</p>

<p>{% gist 710407 %}</p>

<p>To add factory_girl functionality, as well as functionality for factory_girl generators, we need to pull in a few gems into our Gemfile.</p>

<p>{% gist 710412 %}</p>

<p>Run "bundle install" to install the gems. Now let us add a scaffold for a person with first_name and last_name attributes.</p>

<p>{% gist 710417 %}</p>

<p>BOOM! We specified a fixture replacement when generating our scaffold using "-r factory_girl". You will also notice that the scaffold generated a people factory in test/factories/people.rb.</p>

<p>{% gist 710424 %}</p>

<p>That factory looks remarkably similar to a fixture, eh? Great, we are ready to run rake and deploy this application to Heroku.</p>

<p>{% gist 710427 %}</p>

<p>Uh oh. Our functional test for the people controller is still living in fixtureville. So, we need to change that test's setup method to use a factory, not a fixture.</p>

<p>{% gist 710439 %}</p>

<p>And if we run our tests again, SUCCESS!</p>

<p>{% gist 710441 %}</p>

<p>If factory_girl and rails3-generators are tiring you out, <a href="http://blog.agoragames.com/2010/04/09/as-it-turns-out-faking-it-is-ok/">you can always fake it</a>. There is also an ASCIIcast that also describes <a href="http://asciicasts.com/episodes/216-generators-in-rails-3">Generators in Rails 3</a>. You can find more hilarity over on my Twitter account, <a href="http://twitter.com/czarneckid">CzarneckiD</a>.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Nov 22</div></div><div class="blog-content"><h2><a href="/blog/2010/11/22/winning-at-the-career-fair-a-how-to/">Winning at the Career Fair (A How-to)</a></h2><div class="blog-author">By <strong>Clarke Foley</strong></div><div class="blog-body"><p>Recently I had the pleasure of representing Agora Games at two Western New York career fairs held at RIT and my alma mater, University at Buffalo. It was a interesting experience to be on the flip side of the job search process for a change, sitting at our table answering questions, taking resumes, and evaluating applicants' skills to see if they might be the right fit for our team.</p>

<p>One question that was asked repeatedly by fair-goers over the course of the two events was, 'What skills do I need, or what courses should I take, to be the best candidate to work at your company?'. This was a tough question to answer.</p>

<p>The best answer that I could give was, 'There is no predefined skill-set. Today we are looking for Ruby on Rails developers, but tomorrow that may change. In a few months we may be looking for C++ or PHP or Flash devs depending on what we need at the time, so there's no real way to say.'</p>

<p>To hear that probably sounds like a kick in the pants, like there's no way to prepare yourself, but the truth is that the software industry changes so fast that there really isn't any way to predict what technologies will be in style or what skills will be in demand tomorrow. However, there are things you can do to distinguish yourself from other candidates despite this ugly truth. I offered the following prescription:</p>

<ol>
  <li>
    <p>Release code.
 Find or start a project that you're excited about and contribute. It doesn't matter what language or framework, but just get something out there. The best candidates that we found were the ones that showed initiative and put forth extra effort in some little hobby project that they posted on sites like github.</p>
  </li>
  <li>
    <p>Get involved.
 Pick a conference or local user group on some topic that interests you and go! Conferences such as RailsConf, RubyConf, Game Developers Conference (GDC ), and even Penny Arcade Expo (PAX) offer great opportunities to meet and interact with like-minded developers. What could be more fun than hacking on a project together with your new friends? Maybe some of that code could even be released back into the community, or used as samples to show a future employer… hmm…</p>
  </li>
</ol>

<p>In the end, the answer is to do what you love. If your goal is to code, then so do. Get involved and code. The code you produce, experience you gain, and connections you forge will have a beneficial side-effect of making you stand out in any future job search despite any new trend.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Nov 21</div></div><div class="blog-content"><h2><a href="/blog/2010/11/21/pretty-mysql-listings/">Pretty MySQL listings</a></h2><div class="blog-author">By <strong>Jason LaPorte</strong></div><div class="blog-body"><p>Tired of MySQL wrapping long rows when running selects from the command line?  Here's a crazy useful tip:  add \G to the end of your 'select' statement and your output will go from gobbledygook to great.</p>

<p>Here's an example:</p>

<p>{% gist 709399 %}</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Nov 19</div></div><div class="blog-content"><h2><a href="/blog/2010/11/19/ssh-on-os-x-mounting-a-remote-directory-easily/">SSH on OS X: mounting a remote directory easily</a></h2><div class="blog-author">By <strong>Armando DiCianno</strong></div><div class="blog-body"><p>There are many things you can do quickly, and easily, once you have your ssh keys automatically added to your keychain on OSX. One of the more fun things is using MacFUSE to allow you to automatically mount a directory on a remote machine, as if it was a remote share in Finder. This post will show you how.</p>

<p><strong>CAVEAT</strong>: before attempting the steps in this post, please reference <a href="http://blog.agoragames.com/2010/11/17/ssh-keys-agents-and-automation/">my last post</a> about how to setup your ssh keys on OS X.</p>

<hr />
<p>First, dowload and install <a href="http://code.google.com/p/macfuse/">MacFuse</a> if you don't have it yet. You may have it if you've installed 3rd party products like VMware. A good place to check is System Preferences — if you see a control panel for it, click on it, and if it's above version 2.0, then you're good to go. You can download MacFUSE <a href="http://code.google.com/p/macfuse/downloads/list">here</a>, if you don't have it yet.</p>

<p>For the rest of this document, I've generally followed the instructions laid out <a href="http://code.google.com/p/macfuse/wiki/MACFUSE_FS_SSHFS">here</a>, which you may want to referenced.</p>

<p>Run the following sequence of commands in Terminal. Note that you can change the location of "MYDIR", to a spot you prefer. You will need Subversion (svn) installed. The installation of svn is beyond the scope of this post, but consider installing it via <a href="http://www.macports.org/">MacPorts</a>. <strong>UPDATE</strong>: It was pointed out to me that subversion actually ships with OS X, at /usr/bin/svn, so you probably have it installed already.</p>

<p>{% gist 705731 %}</p>

<p>That was pretty straightforward. Now you're ready to test mounting the remote directory. You're going to need a remote server that you can already ssh into. I use the Bash variables VOLNAME and SRVNAME as the name of the folder I want to create locally, and the remote server name, respectively. You'll need to edit these to your liking and needs.</p>

<p>{% gist 705741 %}</p>

<p>Awesomesauce, looks like everything worked. Now, let's automate things a bit, and make a little GUI app that you can click on to mount the share in AppleScript. I've not made this AppleScript too advanced, so make sure to use the fully expanded commands from above. Open "AppleScript Editor", and enter the following code.</p>

<p>{% gist 705745 %}</p>

<p>After you've entered that code into "AppleScript Editor", you're going to want to save it twice.
- Save As -&gt; File Format: Script , for reference.
- Save As -&gt; File Formar: Applicaiton (to run)</p>

<p>Save the application version to somewhere handy for you, such as your Desktop.</p>

<p>For extra bonus points, here's what I do:
- Find a small image, via screen shot, or otherwise, and save it to your Desktop.
- Open the image in Preview, Select All, and Copy.
- Context-click on your AppleScript-saved-as-Application, and select "Get Info"
- Click once on the small icon at the top of the pane that opens.
- Paste.
… and <em>voilà!</em>, you have a handy, easily referencable application-type icon, that you can click on to mount your remote share.
Enjoy, my friends!</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Nov 19</div></div><div class="blog-content"><h2><a href="/blog/2010/11/19/html-and-css-horizontal-delimited-navigation-done-right/">HTML and CSS Horizontal Delimited Navigation Done Right</a></h2><div class="blog-author">By <strong>Joshua Childs</strong></div><div class="blog-body"><p>When we, as front-end developers, set out to build a horizontal site navigation, what markup come to mind? Thoughts of a standard semantic design pattern, an unordered list (UL) with list items (LI) floated to one side, possibly with delimited items to help visually separate each link.</p>

<p>This design pattern generally produces markup that looks something like:</p>

<p>{% gist 704052 %}</p>

<p>And styling like:
 {% gist 704057 %}</p>

<table>
  <tbody>
    <tr>
      <td>This doesn't look so bad, but there's a problem. Those pipes (</td>
      <td>) don't belong in the markup. Because they don't describe any piece of the document, and they are not content, they are purely presentational. As such, they belong in the presentation layer (stylesheets).</td>
    </tr>
  </tbody>
</table>

<p>For a some time now, front-end developers have had to settle for mixing content and presentation in order to maintain a single experience across browsers and platforms due to inconsistent implementations of css2.</p>

<p>Today, notions of one user experience for a website have been shattered by paradigm shifts such as increased market penatration of mobile browsing devices. This shift combined with improved client support for css2 and css3 modules, as seen in IE9pr3, has given us the freedom to build similar but different experiences for users. We are free to build on strengths of each browser while accepting that some browsers may not fully support the presentational features desired.</p>

<p>With that in mind:</p>

<p>{% gist 704060 %}</p>

<table>
  <tbody>
    <tr>
      <td>Our navigation markup now looks the way it should, meaning it's a list of links in no particular order, with only relevant content. There are no pipes (</td>
      <td>) or other delimiters meant only for presentation purposes. The wrapping DIV element has been substituted with a NAV element to be more descriptive.</td>
    </tr>
  </tbody>
</table>

<p>The following CSS does the same basic styling as the first, but notice the last two rules.
 {% gist 704064 %}</p>

<p>The last two rules are how we're able to put those delimiters in the presentation layer. Let's take a closer look.
 {% gist 704067 %}</p>

<p>This rule is adding the pipe (|) delimiter to all of the list (LI) element that have nav.site-nav as their ancestor.
 {% gist 704069 %}</p>

<table>
  <tbody>
    <tr>
      <td>And here we look up the last list item (LI) of our unordered list (UL) and remove the pipe delimiter (</td>
      <td>) we added with the previous rule.</td>
    </tr>
  </tbody>
</table>

<p>Some of you may be saying that this won't work in all browsers (&lt; IE9pr3, &lt; FF3, &lt; Safari4, ect). This is true, it won't work in all browsers, but when you're thinking about doing something like this, ask yourself, "Do I need this for users to be able to use my site?" If yes, then by all means put those load bearing delimiters in your markup. If no, enjoy the knowledge that you can have a more semantic html document, a stylesheet file that takes advantage of modern implementations of css, and a flexible user experience that degrades gracefully in older browsers. Make the move to more cleanly separated content and presentation layers.</p>

<p>You can find more of my musings on the Twitters,  <a href="http://twitter.com/JoshuaChilds">@JoshuaChilds</a>.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Nov 18</div></div><div class="blog-content"><h2><a href="/blog/2010/11/18/working-at-agora-binary_review-1/">Working at Agora #binary_review 1</a></h2><div class="blog-author">By <strong>An Intern</strong></div><div class="blog-body"><p>The following is a (long) binary review of Henryk's experience while working as an intern on the platform team at Agora:</p>

<blockquote>
  <p>For the last 9 months, I co-op'd with Agora as an engineer on the Platform Team. Overall, I'd say the experience was awesome. I had a lot of fun on this co-op. Working at Agora was awesome for many reasons, the people are really friendly, the actual work is difficult and fun, and culture around this company makes working here awesome. I got to do so much here, and learn so much, even putting the programming knowledge aside I've learned so much.</p>
</blockquote>

<p>The people here are awesome. This needed to be repeated for great justice. Everyone here is very welcoming and friendly. They make an attempt to connect with you and help you whenever you're stuck. Everyone listens to what you say and then provides valuable feedback. I always felt like I could ask questions without hesitation. And whenever I did have a problem, I either had someone looking at my screen with me or explaining where I could go to find out more about my problem.</p>

<p>The work here is awesome. For the majority of my co-op, I redesigned and developed the hydra dashboard from the ground up. This was no easy task and required a lot of work. This also included many upgrades from the original that required even more work. I love that I was responsible for such a huge task and that I had so much to work on. Several things had to happen for this be to be complete, a well designed user account system; a better visualization of talking to hydra/simplifying complex data inputs; and getting a new design/layout integrated with the current functionality to mention a few things. Each of these required a sufficient amount of planning, design, and work. And I got to become very skilled with recursion in solving these problems. I learned so much here at this co-op, that I was even inspired to make my own website with the skills I developed here. As a result of working here, I feel like I can solve pretty much any problem if I just learn about it.</p>

<p>The culture here is awesome. I feel comfortable with everyone here, the environment is very relaxed. There's always amusing chat in campfire, we play video games, and we go to lunch for wings regularly. In all seriousness though, it's a very easy environment to settle into. Agora also has hackathons infrequently. These are days when you're part of a team and work for the whole day on one project as a team (come in at midnight if you want!). Even outside of work, you see people doing stuff. Whether it be at a local restaurant, or hosting barbecues, or playing halo on a friday night, it's a fun time working at Agora.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Nov 17</div></div><div class="blog-content"><h2><a href="/blog/2010/11/17/ssh-keys-agents-and-automation/">SSH keys, agents, and automation</a></h2><div class="blog-author">By <strong>Armando DiCianno</strong></div><div class="blog-body"><p>The basis of automating tasks with ssh is setting up your ssh-agent to hold your unlocked keys. Basically, this means never having to type in a password more than once. If you frequently ssh into, run commands on, or copy files to a remote machine, typing in a passphrase over and over gets very tedious.</p>

<p>This post explores integrating one or multiple ssh keys into a normal OS X user session. You'll learn how to create keys, and add them to your OS X Keychain, so you never need to type in your password, after log in, and still have a high level of security.</p>

<p>The author Rita Mae Brow (or Albert Einstein, as the consensus is still out, it seems) was the first that said, "Insanity is doing the same thing over and over again but expecting different results." This is a quote I was thinking about today, when I automated another task related to SSH that I commonly do manually: mounting a directory on a remote server over SSH on OS X.</p>

<p>SSH is one of those protocols that has a very mature suite of tools around it. There are so many wonderful, easy things to do or change that make your workflow more efficient if you use SSH. SSH has first class support in GNU/Linux distributions and Mac OSX, and it can be configured readily into a streamlined workflow.</p>

<p>I use OS X at work, and GNU/Linux on my home machines. This post represents the little bit of learning I had to do to make my nice, automated Linux setup work well on OS X at work. I'm going to go over the basics of ssh key management on OS X in this post, and follow up in another post with mounting a remote directory</p>

<hr />
<p>First, you should already be using ssh to log into remote machines! Hopefully, you're already using ssh keys. If not, here's a quick example about how to setup your first key. The username on my machine is ' <a href="http://en.wikipedia.org/wiki/Fafhrd_and_the_Gray_Mouser">fafhrd</a>', but you should replace that with your own username in the following examples. So, open up Terminal, and …</p>

<p>{% gist 703566 %}</p>

<p>Let's use ssh-add to check the keys in the agent. Note that for some commands, I use the full path. If you're running an install of ssh from <a href="http://www.macports.org/">MacPorts</a> or <a href="http://www.gentoo.org/proj/en/gentoo-alt/prefix/">Gentoo Prefix</a>, you may have to use the full path as well to get the built-in OS X version; this only matters for adding keys.</p>

<p>{% gist 703572 %}</p>

<p>Do you not see any return value? Let's add your key to the agent. In my case, I'm going to add a second key, as well. The following commands will add your keys to the ssh-agent daemon (background process). However, we also want to add the keys to the OS X keychain, so that they're automatically unlocked for you when you log in, so we add the -K flag. This flag does not exist on a stock openssh install, only on the ssh that ships with OS X. Without that flag, the key is only added to the currently running ssh-agent. Note that I'm adding both my keys, and you may just have one. (If your key is already in the keychain, there's no harm adding it again.)</p>

<p>{% gist 703574 %}</p>

<p>At this point, it's important to reboot. Alternatively, if you feel comfortable killing all instances of ssh-agent that are running, you may do so, log out, and log back in. After doing either, open Terminal again, and check for your keys.</p>

<p>{% gist 703576 %}</p>

<p>Great! keychain automatically unlocked the keys for you. Okay, it's time to try it out! If you haven't copied your public keys to your remote server, you should do so now. Your public key is most likely located at ~/.ssh/id_dsa.pub (or id_rsa.pub). Please be sure to use the .pub file, and not the private key! You will want to append (and not necessarily replace) the public key into the file ~/.ssh/authorized_keys, on the remote side.</p>

<p>{% gist 703577 %}</p>

<p>… and test:</p>

<p>{% gist 703582 %}</p>

<p>Nice! The uname command ran on the remote server, and retuned it's data. You should not have been prompted for your password as the credentials are coming straight from your agent.</p>

<p>So what have you actually accomplished? All commands that can use ssh, bundled with the ssh tools (e.g. scp, sftp) or otherwise (e.g. rsync, git, svn), will now never prompt you for your ssh passphrase. This should speed up your workflow, and allow your to automate more of your work. One caveat, though: make sure to lock your workstation when you leave your desk, if you're in an untrusted environment, as someone can open up Terminal, and log into your remote servers easily. However, for the flexibility this automation provides, it's a worthwhile tradeoff.</p>

<p>Let's take this one step further. Want to type even less, by avoiding the "myname@" portion of the ssh command? Create or edit ~/.ssh/config to look like the following.</p>

<p>{% gist 703627 %}</p>

<p>… and now test without the "myname@" portion.</p>

<p>{% gist 703634 %}</p>

<p>The username piece, for any host that matches *.fake.com, automatically uses "myname". Wow, there's so much win right there, it brings a tear to my eye.</p>

<p>In my next post, I'm going to go over mounting remount directories over ssh on OS X. Until then: have fun!</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Nov 16</div></div><div class="blog-content"><h2><a href="/blog/2010/11/16/coding-by-example/">Coding by Example</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>I don't think there's anything inherently wrong in coding by example, e.g. cutting and pasting code from a sample that works for you. But, I would like to advocate for making at least minimal changes to update the code for your application or domain.</p>

<p>Consider the following factory which creates an account.</p>

<p><code>ruby
Factory.define(:account) do |f|
  f.first_name { Factory.next(:name) }
  f.last_name { Factory.next(:name) }
end
</code></p>

<p>What's wrong here? Nothing? What if we change the code to be the following?</p>

<p><code>ruby
Factory.define(:account) do |account|
  account.first_name { Factory.next(:name) }
  account.last_name { Factory.next(:name) }
end
</code></p>

<p>IMO, the second code example is more self-documenting. Obviously we know we're working with a factory, but it's for an account object, and we're being explicit about the attributes being applied to an account object, not some f object which just happens to be an account object.</p>

<p>You can find more hilarity over on my Twitter account, <a href="http://twitter.com/czarneckid">CzarneckiD</a>.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Nov 3</div></div><div class="blog-content"><h2><a href="/blog/2010/11/03/py-amqplib-with-large-messages/">py-amqplib with Large messages</a></h2><div class="blog-author">By <strong>Aaron Westendorf</strong></div><div class="blog-body"><p>At the core of our Hydra platform is AMQP, currently we are using the py-amqplib driver. It has worked well up to this point. We recently had a requirement to send large messages through AMQP, this is where the driver failed us. The following are couple benchmarks and fix to get around the issue.</p>

<p>```python
»&gt; from amqplib import client_0_8 as amqp
»&gt; import time</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>conn = amqp.connection.Connection()
chan = conn.channel()
msg = amqp.Message("1"*(1048576*100))
s = time.time(); chan.basic_publish(msg); print time.time() - s
54.5186219215
```</p>
    </blockquote>
  </blockquote>
</blockquote>

<p>Most of the 54 seconds above was being used in packing the message. This is caused by the following code:</p>

<p>```python
def write_method(self, channel, method_sig, args, content=None):
  payload = pack('&gt;HH', method_sig[0], method_sig[1]) + args</p>

<p>self.dest.write_frame(1, channel, payload)</p>

<p>if content:
    body = content.body
    payload = pack('&gt;HHQ', method_sig[0], 0, len(body)) + \
    content._serialize_properties()</p>

<p>self.dest.write_frame(2, channel, payload)</p>

<p>while body: # HH', method_sig[0], method_sig[1]) + args</p>

<pre><code>self.dest.write_frame(1, channel, payload)
</code></pre>

<p>if content:
    body = content.body
    payload = pack('&gt;HHQ', method_sig[0], 0, len(body)) + \
    content._serialize_properties()</p>

<p>self.dest.write_frame(2, channel, payload)</p>

<p>for payload in self._chunk_body(body, self.frame_max - 8):
    self.dest.write_frame(3, channel, payload)
```</p>

<p>If we run the same test as above with the patched writer_method here is the result:</p>

<p>```python
»&gt; from amqplib import client_0_8 as amqp
»&gt; import time</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>conn = amqp.connection.Connection()
chan = conn.channel()
msg = amqp.Message("1"*(1048576*100))
s = time.time(); chan.basic_publish(msg); print time.time() - s
0.23295211792
```</p>
    </blockquote>
  </blockquote>
</blockquote>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Oct 29</div></div><div class="blog-content"><h2><a href="/blog/2010/10/29/brightcove-gem-1-0-3/">Brightcove gem 1.0.3 </a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>I just pushed out version 1.0.3 of the <a href="http://github.com/agoragames/brightcove">Brightcove gem</a>. This version adds support for performing a file upload, which is useful if you need to create a video in <a href="http://www.brightcove.com/">Brightcove</a>. I did have to add a dependency for <a href="http://github.com/archiloque/rest-client">Rest-Client</a> to support the multipart file upload. Thankfully it all just worked.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Oct 28</div></div><div class="blog-content"><h2><a href="/blog/2010/10/28/random-number-entropy-xen-and-you/">Random Number Entropy, Xen, and You</a></h2><div class="blog-author">By <strong>Jeff Hagadorn</strong></div><div class="blog-body"><p>Here at Agora Games, we are strong proponents of cloud computing for a number of reasons. The ability to scale outward quickly in a time of need continuously aids our processes, encouraging rapid growth and timely response when load increases past the threshold of what our infrastructure can handle. As such, we tend to run most of our applications on scalable cloud providers.</p>

<p>Recently, we decided to move one of our older sites to Rackspace Cloud, which is a relative newcomer to the cloud market who uses Xen for their hypervisor of choice. Here at Agora, we use an efficient application stack that consists of NGINX, which proxies back to haproxy, which in turn load balances to many FastCGI app servers on our backend in order to do the heavy PHP lifting in the most efficient way possible. We have been very happy with the results so far.</p>

<p>After deploying this old site on these shiny new cloud hosts, everything appeared to work great. The site was faster than ever, we had brought all of the web server configs up to date (translated from Apache, which was used on the old hardware based servers), and tuned everything to be lightning quick. Finally, the celebrated day to flip the switch came…</p>

<p>…and the site fell flat on its face within seconds.  All of the servers were idle, memory usage was minimal, there were no IO bottlenecks – we were stumped.</p>

<p>Eventually, we took out an engineer's best friend – strace. Upon running stracing the php threads, we found that each site load was polling from <code>/dev/random</code>, which these days is about as far from a best practice as you can get. Examining the entropy pool, it turned out that it was continuously draining, and waiting to refill, and some old Crypt routines were to blame. We instructed php-mcrypt to use <code>/dev/urandom</code> by way of ﻿﻿﻿﻿<code>MCRYPT_DEV_URANDOM</code>, and pushed the site live again. Suddenly, all servers went green. Success!</p>

<p>To get down to it, the problem is with Xen and how it's virtual drivers work. Apparently, the virtual drivers do not add to the entropy pool for the system's random number generator, causing the pool to empty extremely quickly. The Xen team has known about this problem for a number of years, however it appears they have not fixed it. Using /dev/urandom, which one should always do anyway, eliminates this problem by providing a nonblocking source for random seeding. Yet more proof that going over old code and fixing bad practice can often prove beneficial. :)</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Oct 27</div></div><div class="blog-content"><h2><a href="/blog/2010/10/27/resque-and-resque-unit-in-rails-3/">Resque and Resque Unit in Rails 3</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>Do you need to create background jobs, place those jobs on multiple queues, and process them later? And do you want to test your queue appropriately? Are you using Rails 3?</p>

<p>If your answer to those questions is yes, then you're probably already looking at and using <a href="http://github.com/defunkt/resque">Resque</a> and <a href="http://github.com/justinweiss/resque_unit">Resque Unit</a>. I really just want to cover the nice part about using these libraries in Rails 3. Let's cover the basic setup.</p>

<p><code>Gemfile</code></p>

<p>```ruby
 # Redis/resque</p>

<p>gem 'resque', '1.8.2'
 gem 'redis', '2.0.12'
 gem 'redis-namespace', '0.10.0'</p>

<p>group :test do
 gem 'factory_girl_rails', '1.0'
 gem 'mocha', '0.9.8'
 gem 'resque_unit', '0.2.6'
 end
```</p>

<p><code>config/initializers/resque.rb</code></p>

<p>```ruby
 require 'resque'</p>

<p>redis_config = YAML.load_file("#{Rails.root}/config/redis.yml")
 Resque.redis = redis_config[Rails.env]
 Resque.redis.namespace = "resque:company:namespace"
```</p>

<p><code>config/redis.yml</code></p>

<p><code>ruby
 development: localhost:6379
 test: localhost:6379
 staging: localhost:6379
 production: localhost:6379
</code></p>

<p>Here's the kicker. As we're defining resque_unit in the "test" group in our Gemfile, it's going to "provide a mock Resque for testing Rails code that depends on Resque". Now we can make assertions in our tests about data
 in Resque without having to have Resque running. Pretty simple right?</p>

<p>P.S. The answer to that last question is "yes".</p>

<p>P.P.S. My code in the Gemfile does have indentation, the code formatter on our blog sucks.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Oct 25</div></div><div class="blog-content"><h2><a href="/blog/2010/10/25/hang-in-there-baby/">Hang In There Baby</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p><img alt="" alt="" width="230" height="230" src="/assets/images/uploads/2010/10/Hang-in-There-baby-Inspiration_0E75780C-19617fa2.jpg" /></p>

<p>How long should you keep a git fork around?</p>

<p>Here's the flow: I forked <a href="http://github.com/raw1z/amistad">Amistad</a>, a library for friendships management in Rails 3, to add blocking friends support. I wrote the code, tests, and updated documentation. I generated a pull request for my changes. The author of the library merged those changes into the master branch for Amistad.</p>

<p>**So, how long should I keep my git fork around? **</p>

<p>After writing this post, I'm going to remove the fork because the changes have been integrated into the master branch. I assume that's a reasonable thing to do as there's no divergence between my copy and master. And I don't want anyone to search for my branch, find it, use it, and then later have issues that a) need to be fixed or b) want to contribute more functionality. I want all of that to happen in the library's master branch.</p>

<p>Is that reasonable? Or is there a period of time I should keep my fork around for? Am I overthinking this? I'd just like to know if there's a better workflow or standard that the community has adopted in this regard.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Oct 25</div></div><div class="blog-content"><h2><a href="/blog/2010/10/25/amistad-friendships-in-rails-3/">Amistad: Friendships in Rails 3</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>If you're looking for a way to do friendships in Rails 3, you might have a look at <a href="http://github.com/raw1z/amistad">Amistad</a>. I added support for blocking friendship requests and <a href="http://github.com/raw1z/amistad/commit/28ad024bda7a46a28de13a65d499e2318aa4c352">those changes</a> have been integrated into master. One of the benefits of contributing this code was I got some exposure to <a href="http://rspec.info/">RSpec</a>.</p>

<p>Enjoy!</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Oct 19</div></div><div class="blog-content"><h2><a href="/blog/2010/10/19/getting-cozy-with-shorthand-css-properties/">Getting Cozy with Shorthand CSS Properties</a></h2><div class="blog-author">By <strong>Joshua Childs</strong></div><div class="blog-body"><p>I pride myself in being forgetful, but sometimes this can have unfortunate consequences. For instance, whenever I want to use the <a href="http://www.devarticles.com/c/a/Web-Style-Sheets/CSS-shorthand-at-a-glance/3/">css background shorthand property</a> I simply can't remember the order.</p>

<p>In case you aren't aware, the background shorthand basically allows you to specify a background all at once, that would otherwise need to be specified with multiple rules.</p>

<p>For example</p>

<p><code>css
background-color: black
background-attachment: fixed
background-position: left top
background-repeat: no-repeat
background-image: url(example.gif)
</code></p>

<p>simply becomes</p>

<p><code>css
background: url(example.gif) no-repeat fixed left top black
</code></p>

<p>And the whole world is happy…</p>

<p>As I mentioned the problem is I find it difficult to remember the order, and it seems that there is an order that should be followed, if for no reason other than consistency. As a result I always find myself turning to Google to remember what that order is. This is frustrating, but even more frustrating Google never returns the result I'm looking for and I end up leafing through several results to eventually stumble upon a code example that can help me.</p>

<p>Well, not anymore! Turns out there is an easier way then this and one which doesn't require me to resort to hardcore memorization (my only weakness). As anyone who really knows me is already aware, I love <a href="http://getfirebug.com/">Firebug</a>. The reasons go on and on, but now I have a new one. Firebug automatically fixes the background style rule providing the complete and proper format. If you specify a background rule and just give it say a color, or take your best shot at specifying all the properties you need then leave the style pane for a second or two and close your eyes, by the time you come back Firebug would have parsed and updated your best effort with the correct format. How nice.</p>

<p>Once I realized this, I couldn't help but share my excitement with some of the fellows around the office. Well, our new teammate Nick pointed out that it would be cool if this worked for the font shorthand as well; I thought so too. As it turns out however, it does not. That's really too bad, but maybe we will see this feature come along in the future. I think it would be a welcomed addition all around to an already spectacular tool. Thanks Firebug!</p>

<p>For anyone who wants to know a little more about all the CSS shorthand rules here is a <a href="http://www.devarticles.com/c/a/Web-Style-Sheets/CSS-shorthand-at-a-glance/">nice article I found on the nets about it</a>.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Oct 11</div></div><div class="blog-content"><h2><a href="/blog/2010/10/11/agora-visits-the-university-at-albany-career-fair/">Agora visits the University at Albany Career Fair </a></h2><div class="blog-author">By <strong>Clarke Foley</strong></div><div class="blog-body"><p>Ernst and Young recruiters gave away silver pens, designer platinum-cased post it notes and travel coffee mugs. KPMG gave away environmentally friendly thermos bottles and key chains. They also had a really, really nice sign.</p>

<p>Then there was Agora Games…
Being new to the recruiter role, Blake and I wore our beards and normal work attire, which included one mohawk and an obnoxious pair of florescent yellow Nikes. While perhaps not as sharp as other recruiter’s suits and ties, we were definitely dressed for success.</p>

<p>The UAlbany Career fair saw hundreds of students from several degree programs trying to get a feel for which industries and companies were scouting future hires. As the university is known for its strong business school, we were offered numerous resumes from accounting, business administration and communications majors. A welcomed change of pace from our everyday engineering-focused mindset, it was interesting to chat with English majors, marketing majors, and the surprisingly frequent–and not surprisingly somewhat pushy–“my boyfriend plays video games all the time, can he work there?” career fair candidate.</p>

<p>As interesting as this was, we were on a mission that was a bit more technically focused. Our goal: track down as many people as possible who were interested in Ruby on Rails, Python, JQuery, or Flash, while using our less than KPMG-worthy sign. We were given resumes from computer science  and information science majors, and information technology management buffs. Scouring the selection, scarcely did we find that "gem" we were looking for…literally, nobody knew what a Ruby Gem was. (har har!) All puns aside, we're continually finding this to be the case at most of the college career fairs we visit. In this university setting, to a polytechnic institute setting, (yes, reference intended), it seems that the most valuable coding language and most sought-after job skill in today’s software development field is concurrently the least taught.</p>

<p>As we collected information on the student’s school-based skill sets, it was clear that the top engineer of tomorrow might also be the person who is learning coding languages on their own. Take heed, soon-to be-grads; spend a few weekends brushing up on some of the aforementioned languages. Scout outside the classroom walls to see what languages the smaller, innovative companies are using. Scour Craigslist to get a feel for what types of development work is being outsourced in your area. Who knows, you might see Blake and I at your upcoming career fair, mohawks and yellow sneakers adorned, looking for the next Ruby Wizard.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Oct 7</div></div><div class="blog-content"><h2><a href="/blog/2010/10/07/testlink-bringing-order-to-testing/">Testlink - bringing order to testing</a></h2><div class="blog-author">By <strong>Devon Smith</strong></div><div class="blog-body"><p><a href="http://www.teamst.org/"> <img alt="TestLink" title="testlink_logo_2" src="http://ladybug010.wordpress.com/files/2009/12/testlink_logo_2.jpg?w=150" /> </a></p>

<p>If you start searching for test tracking and management software, you will run into Testlink. Although far from perfect, Testlink does some pretty cool things.  In the past, I kept track of my tests on proprietary software or open office spreadsheets, which are functional- but the organization offered by testlink moved my whole testing approach to a new level.</p>

<p><strong>The Good:</strong></p>

<p>Open Source</p>

<p>Test case/requirements/test plan organization</p>

<p>requirements management</p>

<p>requirements based testing</p>

<p>result reporting</p>

<p>central location for assigning, approving and executing tests</p>

<p><strong>The Bad:</strong></p>

<p>It is a bit clunky to use</p>

<p>UI is pretty horrible</p>

<p>Minor bugs and unfinished features</p>

<p>Isn't set up for a ton of integration- but there is an API</p>

<p><strong>The results:</strong></p>

<p>This tool opens up the testing process for anyone on the project to be aware of what QA is working on. Communication between QA and Devs can be improved (as everyone can access and review test cases or requirements), and the approval process is much easier and more organic than holding a big meeting. Test link has the potential for seamless integration with bug filing  helping to carefully order and maintain a tester's world. It doesn't come pre-linked to much, but the site does offer some instructions on setting it up yourself. It does offer a good user guide and a pretty active community for support.</p>

<p>You can input your documents (I haven't found a way to do this automatically, but manually putting them in does ensure that you do careful ambiguity review) and then link each requirement to a test case, or generate test cases right from the requirement. The execute section can accept xml results and notes. Testlink automatically generates test plans and test reports with data from the system, so you can put out a document that shows your test plan, and then gives overviews of your test cases and tracks the requriements. It has been extremely useful for increasing transparency in the QA department and keeping everyone involved with the process. There is a way to create custom fields, which I have been used for test plan approvals and linking to bugs filed from the execute screen.</p>

<p>In all, it is a great program- that could use some finishing tweaks and an UI overhaul. I can look past its flaws though for the functionality it provides. The functionality really is pretty cool. For multiple projects and teams, it makes organizing the test process easy.  Testlink is a great little program that can act as a hub for testing related activities.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Oct 6</div></div><div class="blog-content"><h2><a href="/blog/2010/10/06/data-relationships-in-nosql/">Data relationships in NoSQL (P.S. They're real and they're spectacular)</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>Do people really think there are no relationships between data in NoSQL databases? Or that they're doomed from the start?</p>

<p><img alt="" title="This Relationship Is Doomed" src="http://www.nataliedee.com/092808/this-relationship-is-doomed.jpg" /></p>

<p>I'm going to demonstrate a very simple relationship among data using <a href="http://www.mongodb.org/">MongoDB</a> and <a href="http://mongoid.org/">Mongoid</a>.</p>

<p>Let's first define a user.</p>

<p>```ruby
class User
  include Mongoid::Document
  include Mongoid::Timestamps</p>

<p>attr_protected :_id</p>

<p>field :nickname
  field :first_name
  field :last_name</p>

<p>references_many :activity_items
end
```</p>

<p>Users are an active bunch, so let's keep track of their activity. The user model references the activity items.</p>

<p>```ruby
class ActivityItem
  include Mongoid::Document
  include Mongoid::Timestamps</p>

<p>attr_protected :_id</p>

<p>field :event_type</p>

<p>referenced_in :user</p>

<p>index :user
end
```</p>

<p>The activity item references a user.</p>

<p>Now, let me show you how this works.</p>

<p><code>ruby
dczarnecki-agora:project dczarnecki$ rails console
Loading development environment (Rails 3.0.0)
ruby-1.9.2-p0 &gt; user = Factory.create(:user)
=&gt; #
ruby-1.9.2-p0 &gt; activity = Factory.create(:activity_item, :user =&gt; user)
=&gt; #
ruby-1.9.2-p0 &gt; user.activity_items.count
=&gt; 1
ruby-1.9.2-p0 &gt; activity.user
=&gt; #
ruby-1.9.2-p0 &gt;
</code></p>

<p>I created a user. I created an activity and associated it with the user I just created. I counted the number of activities of that user. I referenced the user from the activity.</p>

<p>Any questions?</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Sep 22</div></div><div class="blog-content"><h2><a href="/blog/2010/09/22/cookie-monster/">Cookie Monster</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>I thought if you didn't use Rails sessions, that Rails wouldn't create a session cookie?</p>

<p><img alt="" alt="" width="300" height="290" src="/assets/images/uploads/2010/09/cookie-monster3-7769871237963363-300x290-bb35364e.jpg" /></p>

<p>In any event, one of our engineers had put together a simple Rack middleware for destroying cookies.</p>

<p>You can find the <a href="http://gist.github.com/592330">code for cookie_monster.rb as a Gist on GitHub</a>.</p>

<p>If this helps you, great. I'd also like to understand why a session cookie gets created? It seems like it's happening in the bowels of Rails. This is a Rails 2.3.8 application by-the-dubz.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Sep 10</div></div><div class="blog-content"><h2><a href="/blog/2010/09/10/rails-3-mocha-load-order-gotcha/">Rails 3 + Mocha Load Order Gotcha</a></h2><div class="blog-author">By <strong>Tom Quackenbush</strong></div><div class="blog-body"><p>The other day we ran into an issue in one of our new Rails 3 apps that is using mocha for mocking. It seemed that once a stub was mocked in one test, it would carry over to each subsequent test causing failures.
 Mocks were not being torn down correctly…
 Since mocha does not lie, it had to be something within our setup causing it to fail…</p>

<p>Thankfully, a tweet response from @elise_huard offered the following solution:</p>

<p>" <a href="http://www.twitter.com/tquackenbush">@tquackenbush</a> yes, <a href="http://www.twitter.com/threedaymonk">@threedaymonk</a> suggested a fix: to fix load order, so do <code>gem 'mocha', :require =&gt; false</code> and <code>require 'mocha'</code> in test_helper"</p>

<p>Worked like a charm!
 A tip of the hat to <a href="http://www.twitter.com/elise_huard">@elise_huard</a> and <a href="http://www.twitter.com/threedaymonk">@threedaymonk</a> for the help!</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Aug 16</div></div><div class="blog-content"><h2><a href="/blog/2010/08/16/a-look-backa-look-ahead-videogames-of-200920102011/">A Look Back/A Look Ahead: Video games of 2009/2010/2011</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>I love video games.</p>

<p>Here is a look at the games I played in 2009 and 2010 (so far) and a look ahead to the rest of this year as well as 2011. And when I say played, I mean played through to completion.</p>

<p><strong>2009</strong></p>

<p>30 games in total.</p>

<p><strong>360</strong></p>

<ul>
  <li>Silent Hill Homecoming</li>
  <li>F.E.A.R</li>
  <li>F.E.A.R. 2 (Project Origin)</li>
  <li>Halo Wars</li>
  <li>Call of Duty: World at War</li>
  <li>Guitar Hero: Metallica</li>
  <li>Mirror's Edge</li>
  <li>RESIDENT EVIL 5</li>
  <li>Guitar Hero: Hits</li>
  <li>Batman: Arkham Asylum</li>
  <li>Ghostbusters</li>
  <li>Fallout 3</li>
  <li>[PROTOTYPE]-</li>
  <li>Section 8</li>
  <li>Guitar Hero 5</li>
  <li>Band Hero</li>
  <li>Guitar Hero: Van Halen</li>
  <li>Halo 3: ODST</li>
  <li>ZOMBIE APOCALYPSE (XBLA)</li>
  <li>Brütal Legend</li>
  <li>Borderlands</li>
  <li>Left 4 Dead 2</li>
  <li>Call of Duty: Modern Warfare 2</li>
  <li>Assassin's Creed II</li>
</ul>

<p><strong>PS3</strong></p>

<ul>
  <li>inFamous</li>
  <li>Uncharted (Drake's Fortune)</li>
  <li>Uncharted 2 (Among Thieves)</li>
  <li>Ratchet &amp; Clank Future: Tools of Destruction</li>
</ul>

<p><strong>Nintendo DS</strong></p>

<ul>
  <li>Treasure World</li>
  <li>Scribblenauts</li>
</ul>

<p><strong>2010</strong></p>

<ul>
  <li>Dante's Inferno</li>
  <li>Mass Effect 2</li>
  <li>Battlefield: Bad Company 2</li>
  <li>BioShock 2</li>
  <li>Alan Wake</li>
  <li>Blur</li>
  <li>Naughty Bear</li>
  <li>Red Dead Redemption</li>
  <li>The Simpsons Game</li>
  <li>LIMBO (XBLA)</li>
</ul>

<p><strong>August 2010</strong></p>

<ul>
  <li>Saints Row 2</li>
</ul>

<p><strong>September 2010</strong></p>

<ul>
  <li>Halo: Reach</li>
  <li>Guitar Hero: Warriors of Rock (*) - Technically I've already beaten this game ;)</li>
</ul>

<p><strong>October 2010</strong></p>

<ul>
  <li>Lucha Libre AAA Heroes of the Ring</li>
  <li>Fallout: New Vegas</li>
  <li>Rock Band 3</li>
</ul>

<p><strong>November 2010</strong></p>

<ul>
  <li>Call of Duty: Black Ops</li>
  <li>LittleBigPlanet 2</li>
</ul>

<p><strong>2011</strong></p>

<p><strong>January 2011</strong></p>

<ul>
  <li>Lord of the Rings: War in the North</li>
  <li>Dead Space 2</li>
</ul>

<p><strong>February 2011</strong></p>

<ul>
  <li>Brink</li>
  <li>Bulletstorm</li>
</ul>

<p><strong>March 2011</strong></p>

<ul>
  <li>Portal 2</li>
  <li>F.E.A.R. 3</li>
  <li>Gears of War 3</li>
  <li>Red Faction: Armageddon</li>
</ul>

<p>What else am I missing? What should I be playing? What are you playing?</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Aug 5</div></div><div class="blog-content"><h2><a href="/blog/2010/08/05/hackaton/">Hackathon</a></h2><div class="blog-author">By <strong>Mike DelPrete</strong></div><div class="blog-body"><p>Working at MLG/Agora is pretty inspiring, and having the Wall Of Fame located directly opposite the door to my office continually reinforces my opinion. The wall's best feature is the newest team photo taken just after our recent Hackathon.</p>

<p>What's a Hackathon you ask? It's eight teams, 24 hours, and the requirement to work on something, anything, so long as you have a working demo by the end of the event. The results? Four software products, three internal tools, two infrastructure improvements, one video-enabled conference room and a theme song for Hydra.  A good time was had by all.</p>

<p><img alt="image" alt="" width="500" height="282" src="/assets/images/uploads/2010/08/wpid-2010-08-05_14-41-34_674-692ffd55.jpg" /></p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Aug 5</div></div><div class="blog-content"><h2><a href="/blog/2010/08/05/the-strophe-js-echobot/">The Strophe.js Echobot</a></h2><div class="blog-author">By <strong>Armando DiCianno</strong></div><div class="blog-body"><p>I'm toying around with in-browser XMPP in order to publish information to our users in real time.  To start, I wanted to get the strophe.js echobot demo working.  I found the posted steps a bit lacking, and thus I present a more detailed procedure for how to get nginx+ejabberd+strophe.js up and running on Ubuntu 10.04 Workstation.  When we're finished, we'll test using Firefox and Empathy.</p>

<p>Note: The process should be the same for a Ubuntu server, though you'll have to futz with hostnames and test using your workstation or something like irssi+bitlbee.</p>

<p><strong>Installation</strong></p>

<ol>
  <li>Install nginx and ejabberd</li>
</ol>

<p><code>
foo@bar$ sudo apt-get install ejabberd nginx curl
</code></p>

<ol>
  <li>Download strophe.js</li>
</ol>

<p><code>
foo@bar$ curl - http://code.stanziq.com/strophe/strophejs/releases/strophejs-1.0.1.tar.gz
</code></p>

<p><strong>Verify your machine config</strong></p>

<ol>
  <li>Verify you have an entry in your /etc/hosts file for localhost, it should look something like this (yes, silly, but lately for some reason I keep running into people who modify this incorrectly):</li>
</ol>

<p><code>
#/etc/hosts
127.0.0.1 localhost
</code></p>

<p><strong>Configuring ejabberd</strong></p>

<ol>
  <li>Setup account admin account</li>
</ol>

<p><code>
foo@bar$ sudo ejabberdctl register admin localhost admin
</code></p>

<ol>
  <li>Edit /etc/ejabberd/ejabberd.cf and make the following changes.</li>
</ol>

<p>In the admin user section, add the username "admin" so that it looks like this:</p>

<p><code>
%% ejabberd.cfg
%% Admin user
{acl, admin, {user, "admin", "localhost"}}.
</code></p>

<p>In the modules section add mod_http bind to the list of loadable modules:</p>

<p><code>
%% ejabberd.cfg
%%
{modules,
[
...
{mod_http_bind, []},
...
]
}.
</code></p>

<ol>
  <li>Restart ejabberd</li>
</ol>

<p><code>
foo@bar$ sudo /etc/init.d/ejabberd restart
</code></p>

<ol>
  <li>Verify ejabberd is working by browsing to http://localhost:5280/http-bind</li>
</ol>

<p><strong>Configuring nginx</strong></p>

<ol>
  <li>Create /etc/nginx/sites-available/strophe and include the following:</li>
</ol>

<p>```
#nginx.conf
server {
listen 8080;
server_name localhost;</p>

<p>location /http-bind {
proxy_buffering off;
tcp_nodelay on;
keepalive_timeout 55;
proxy_pass http://localhost:5280;
}</p>

<p>location / {
# This is where you place your strophejs sample.
root /var/www/strophe;
}
}
```</p>

<p>Note: If for whatever reason the new configuration conflicts with an existing one, you can probably get by if you change the port number.  I used 8080 so that this won't conflict with the default config.</p>

<ol>
  <li>
    <p>Symlink the config to the sites-enabled folder
<code>
foo@bar$ sudo ln -s /etc/nginx/sites-available/strophe strophe
</code></p>
  </li>
  <li>
    <p>Be a good little sysadmin and check your work.</p>
  </li>
</ol>

<p><code>
foo@bar$ sudo nginx -t
the configuration file /etc/nginx/nginx.conf syntax is ok
configuration file /etc/nginx/nginx.conf test is successful
</code></p>

<ol>
  <li>If it passes, restart nginx</li>
</ol>

<p><code>
foo@bar$ sudo /etc/init.d/nginx restart
</code></p>

<p><strong>Setup strophe.js</strong></p>

<ol>
  <li>
    <p>From the directory where you downloaded strophe
<code>
foo@bar$ tar -xzvf strophejs-1.0.1.tar.gz
foo@bar$ sudo mv strophejs-1.0.1 /var/www/strophe
</code></p>
  </li>
  <li>
    <p>Modify /var/www/strophe/exampl/echobot.js
<code>javascript
// echobot.js
var BOSH_SERVICE = 'http://localhost:8080/http-bind'
</code></p>
  </li>
</ol>

<p>Test!</p>

<ol>
  <li>
    <p>Open Firefox and go to: <a href="http://localhost:8080/examples/echobot.html">http://localhost:8080/examples/echobot.html</a></p>
  </li>
  <li>
    <p>Enter the following:</p>
  </li>
</ol>

<p>JID: admin@localhost
Password: admin</p>

<ol>
  <li>
    <p>Click connect, it will show message like this.
Strophe is connecting.
Strophe is connected.
ECHOBOT: Send a message to admin@localhost.local/4199388567126350847984920 to talk to me.</p>
  </li>
  <li>
    <p>Open Empathy and create a new Jabber account.</p>
  </li>
</ol>

<p>Login: admin@localhost
Pass: admin</p>

<ol>
  <li>
    <p>Initiate a new chat with the contact id shown in the web browser, in my case: admin@localhost.local/4199388567126350847984920</p>
  </li>
  <li>
    <p>Type a message, and it will appear in the browser.</p>
  </li>
</ol>

<p>Done!</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Jul 29</div></div><div class="blog-content"><h2><a href="/blog/2010/07/29/brightercove/">Brightercove</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>We're using <a href="http://www.brightcove.com/en/">Brightcove</a> here at Agora Games for some video platform work. In our group chats, we've talked about, "It would be nice if we had a Ruby API for interacting with Brightcove."</p>

<p>And so I did just that, <a href="http://github.com/agoragames/brightcove">http://github.com/agoragames/brightcove</a></p>

<p>```ruby
sudo gem install brightcove-api</p>

<blockquote>
  <blockquote>
    <p>require 'brightcove-api'
=&gt; true
brightcove = Brightcove::API.new('0Z2dtxTdJAxtbZ-d0U7Bhio2V1Rhr5Iafl5FFtDPY8E.')
=&gt; #
response = brightcove.get('find_all_videos', {:page_size =&gt; 3, :video_fields =&gt; 'id,name,linkURL,linkText'})
=&gt; {"items"=&gt;[{"name"=&gt;"Documentarian Skydiving", "id"=&gt;496518762, "linkText"=&gt;nil, "linkURL"=&gt;nil}, {"name"=&gt;"Surface Tricks", "id"=&gt;496518763, "linkText"=&gt;nil, "linkURL"=&gt;nil}, {"name"=&gt;"Free Skiing", "id"=&gt;496518765, "linkText"=&gt;nil, "linkURL"=&gt;nil}], "page_number"=&gt;0, "page_size"=&gt;3, "total_count"=&gt;-1}
```</p>
  </blockquote>
</blockquote>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Jul 29</div></div><div class="blog-content"><h2><a href="/blog/2010/07/29/party-for-misha/">Party for Misha</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p><img alt="image" alt="" width="500" height="375" src="/assets/images/uploads/2010/07/wpid-1280422338861-c8d1d87f.jpg" /></p>

<p>Today is Misha's last day.  We wished him luck and toasted him off with some local microbrews from the Troy Pub and Brewery.</p>

</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Jul 28</div></div><div class="blog-content"><h2><a href="/blog/2010/07/28/grabbing-the-rabbit-by-the-horns/">Grabbing the Rabbit by the Horns</a></h2><div class="blog-author">By <strong>Aaron Westendorf</strong></div><div class="blog-body"><p>RabbitMQ is a very powerful tool, especially when deployed in a cluster. Among RabbitMQ's more useful features is rabbitmqctl, the command line tool which can be used to query a node and list its exchanges, queues, connections, number of consumers, memory usage and more.</p>

<p>The application, and cluster deployment in general, is hamstrung by Erlang's standard approach to cookies. The cookie, typically .erlang.cookie in the HOME directory of an application, must have only user read permissions. For a Linux RabbitMQ install, that would look like this:</p>

<p><code>
bofh@rabbit_host1:~$ ls -al /var/lib/rabbitmq/
total 333
drwxr-xr-x 3 rabbitmq rabbitmq 160 2010-07-12 17:49 .
drwxr-xr-x 37 root root 1008 2010-07-02 14:29 ..
-r-------- 1 rabbitmq rabbitmq 20 2010-05-04 20:44 .erlang.cookie
drwxr-xr-x 3 rabbitmq rabbitmq 72 2010-05-04 20:49 mnesia
-rw-r--r-- 1 rabbitmq rabbitmq 27 2010-07-12 17:49 pids
</code></p>

<p>Any variation on these permissions and Erlang will refuse to start. The permissions requirement is embedded into Erlang itself, making it more or less impossible to work around. This creates the following problems:</p>

<ul>
  <li>You must copy this file (or its contents) to all hosts in the cluster</li>
  <li>All users of rabbitmqctl must run it as sudo</li>
  <li>All monitoring tools must also run as root or have sudo capability</li>
  <li>You must have the cookie file present on the host running rabbitmqctl</li>
</ul>

<p>Given how powerful rabbitmqctl is, you will likely still want to limit access to it, but this can be readily accomplished with standard Unix permissions. By expanding who can use it and where, your system administrator will be thrilled to reduce need for sudo access and your customers will be happy with the additional tools you can deploy to monitor your cluster and its clients to ensure that all is well, 24/7.</p>

<p>Thankfully, RabbitMQ's scripts accept a lot of environment variables which can be passed into the Erlang runtime, and Erlang kindly provides a way to bypass the cookie file through a command line literal. The scripts are all located in the scripts directory inside your RabbitMQ installation.</p>

<p><code>
bofh@rabbit_host:~$ ls -ald `erl -eval 'io:format("~s~n", [code:lib_dir()])' -s init stop -noshell`/rabbitmq-server\*/scripts
drwxr-xr-x 2 root root 520 2010-07-21 14:47 /usr/local/lib/erlang/lib/rabbitmq-server-1.7.0/scripts
drwxr-xr-x 2 root root 520 2010-07-21 16:15 /usr/local/lib/erlang/lib/rabbitmq-server-1.7.2/scripts
</code></p>

<p>The three standard scripts, rabbitmq-server, rabbitmq-multi and rabbitmqctl all source an environment script, rabbitmq-env, which in turn will source the file /etc/rabbitmq/rabbitmq.conf if it exists. This is the file that you can edit to take control of your RabbitMQ cluster.</p>

<p><code>
SERVER_START_ARGS="+K true +A300 +P512000 -setcookie NOMNOMNOMYUMYUM -kernel inet_default_listen_options [{nodelay,true},{sndbuf,32768},{recbuf,32768}]"
MULTI_START_ARGS="-setcookie NOMNOMNOMYUMYUM"
CTL_ERL_ARGS="-setcookie NOMNOMNOMYUMYUM"
</code></p>

<p>The value of each environment variable will be passed verbatim to the Erlang runtime. The <code>SERVER_START_ARGS</code> are passed to each node started by rabbitmq-multi, and directly affect the performance of a RabbitMQ instance. In this example, we have increased the number of native threads available to Erlang and allowed it to spin up numerous (Erlang) processes. We have also instructed the kernel to increase its TCP buffer sizes and disable Nagle's algorithm.</p>

<p>You can now run rabbitmqctl without sudo on any host which has this same configuration deployed. This solution still requires that you synchronize /etc/rabbitmq across your cluster, though there are many ways of solving that problem.</p>

<p>We have taken this a step further and enabled rabbitmqctl on any host in our network. All of our core software is deployed from source to /usr/local over NFS. We have deployed the rabbitmq.conf file there too, and have a small shell script wrapping rabbitmqctl.</p>

<p>```
#!/bin/bash
ERL_PATH=<code>erl -eval 'io:format("~s~n", [code:lib_dir()])' -s init stop -noshell</code>
LATEST_VERSION=<code>ls $ERL_PATH | grep rabbitmq | sort | tail -1</code>
RABBIT_PATH="$ERL_PATH/$LATEST_VERSION"</p>

<p>set -f
[ -f /usr/local/etc/rabbitmq/rabbitmq.conf ] &amp;&amp; . /usr/local/etc/rabbitmq/rabbitmq.conf
export CTL_ERL_ARGS
HOME=/var/lib/rabbitmq $RABBIT_PATH/scripts/rabbitmqctl $@
```</p>

<p>We can now connect to and monitor any RabbitMQ node from any host on our network</p>

<p><code>
bofh@gateway:~$ rabbitmqctl -n rabbit@rabbit_host1 status
Status of node rabbit@rabbit_host1 ...
[{running_applications,[{rabbit,"RabbitMQ","1.7.2"},
{mnesia,"MNESIA CXC 138 12","4.4.10"},
{os_mon,"CPO CXC 138 46","2.2.2"},
{sasl,"SASL CXC 138 11","2.1.6"},
{stdlib,"ERTS CXC 138 10","1.16.2"},
{kernel,"ERTS CXC 138 10","2.13.2"}]},
{nodes,[rabbit@rabbit_host1,rabbit@rabbit_host2]},
{running_nodes,[rabbit@rabbit_host1,rabbit@rabbit_host2]}]
...done.
</code></p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Jul 27</div></div><div class="blog-content"><h2><a href="/blog/2010/07/27/rails-3-0-0-rc-changes/">Rails 3.0.0.rc changes</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>Rails 3.0.0 now has a <a href="http://weblog.rubyonrails.org/2010/7/26/rails-3-0-release-candidate">release candidate</a>. These are the changes I made to a new application I am working on to clear up any deprecation warnings.</p>

<p><strong>Gemfile</strong></p>

<p>gem 'rails', '3.0.0.rc'
 gem 'haml', '3.0.14'</p>

<p>Obviously you have to tell your application to use the 3.0.0.rc. Also, it seems as if haml 3.0.13, which we were previously using, had some incompatible changes with Rails 3.0.0.rc</p>

<p><strong>Rakefile</strong></p>

<p>Change:</p>

<p>Rails::Application.load_tasks</p>

<p>to:</p>

<p>YourApplicationName::Application.load_tasks</p>

<p><strong>config/environments/test.rb</strong></p>

<p>Add:</p>

<p>config.active_support.deprecation = :stderr</p>

<p><strong>config/routes.rb</strong></p>

<p>Change:</p>

<table>
  <tbody>
    <tr>
      <td>YourApplicationName::Application.routes.draw do</td>
      <td>map</td>
    </tr>
  </tbody>
</table>

<p>to:</p>

<p>YourApplicationName::Application.routes.draw do</p>

<p>Rails 3 routing in great detail: <a href="http://www.engineyard.com/blog/2010/the-lowdown-on-routes-in-rails-3/">The Lowdown on Routes in Rails 3</a>.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Jun 28</div></div><div class="blog-content"><h2><a href="/blog/2010/06/28/lifting-the-tail-inside-agora-skunk-works/">Lifting the Tail: Inside Agora Skunk Works</a></h2><div class="blog-author">By <strong>Aaron Westendorf</strong></div><div class="blog-body"><p>We've been hard at work for over a year developing the next generation of game integration technology here at Agora, and over the next few months we'll be releasing some of the code that we've developed, discussing some of the challenges we face and how we're using all the new technology to build the best gaming experience around.</p>

<p>To start, a brief explanation of the challenges we face.  As you might imagine, we deal with a lot of data.  The volume is only increasing, and with our friends at MLG, we expect significantly more of it.  Along with the volume of data, it also comes to us in many different forms and protocols; sometimes it's pushed to us, and sometimes we have to go fetch it.  We have to respond to any number of business decisions made by developers and publishers, adapt to developers' needs in a manner which does not negatively impact their schedule, and be a consistent and reliable partner to all our clients.  We have to deliver comprehensive documentation to both game and website developers, and our business relationships are aided by a consistent offering.
 </p>

<p>In the past, each game's services would be its own Rails application.  We built a suite of re-usable components, but for each title we would have to re-write a lot of boiler-plate code and set up an entirely new suite of servers, complete with application hosts, web and caching proxies, databases and so on.  As our data throughput grew, we found that we needed to add additional components to our stack, such as Sparrow, to turn synchronous workloads into asynchronous ones.  Each project required extensive monitoring and reporting, an interactive console for viewing production data and testing staging code.
 </p>

<p>We were very successful, but found the business costs too high and that we were missing several features that were important to our long term strategy of being the best in the industry at game integration.  Our experience with a virtualized hosting environment opened our eyes to the possibilities of turning our data processing and web services loose on a commoditized, shared platform.
 </p>

<p>With a general set of requirements in hand, we set forth, and what we came away with has been incubating, gestating and flowering into a powerful toolset that has met all our expectations, and then some.
 </p>

<p>Our first task was to choose the core set of technologies and the basic processing scheme that we would be using.  After an exhaustive search, lots of hacking and whiteboard scribblings, we settled on the following key features:
 
- Python for all application code
- <a href="http://www.amqp.org">AMQP</a>, via <a href="http://www.rabbitmq.com">RabbitMQ</a>, for all inter-process communication
- MySQL, Tokyo Tyrant and memcache for data storage services
- Protocol translators to bridge external traffic to AMQP via a simple binary protocol
- libevent for as many as IO operation as possible</p>

<p><img alt="" title="lifting the tail" alt="" width="357" height="193" src="/assets/images/uploads/2010/06/lifting_the_tail-85c282ad.png" />
 </p>

<p>We chose Python from the suitable dyanmic languages primarily for its memory management and speed.  We were shifting to a single-threaded multi-process environment where memory costs are high and performance paramount, and Python has an extensive pedigree in this area.  We did choose to sacrifice some memory by adhering to a single-threaded model in order to keep the application stack simple and use the kernel for all context switching.
 </p>

<p>AMQP's routing scheme gives us powerful tools to shard and aggregate traffic across our cluster.  We chose RabbitMQ because of its Erlang heritage, its performance, reliability, clustering capabilities and commercial support.  By splitting up each game's services into discrete packages which can each run numerous instances, we can readily divide traffic across a cluster of RabbitMQ hosts and attach listeners for monitoring, diagnostics and metrics.  The dotted-notation of AMQP's topic exchanges allow for routing traffic between titles, environments, services and even specific commands.
 </p>

<p>To get the most out of the kernel and reduce latency, we use <a href="http://monkey.org/~provos/libevent/">libevent</a> for all of our AMQP traffic and in our protocol translators.  We extensively patched the <a href="http://barryp.org/software/py-amqplib/">py-amqplib</a> to work within this asynchronous environment.  This fork has been in production use for some time now but is slated for a ground-up re-write and release into the wild.
 </p>

<p>We considered many other database solutions, but at the time that we had to make our decision, felt that Tokyo Tyrant was the best NoSQL database to introduce into our stack because of its sparse table capabilities, high performance, low resource usage and simple setup.  We're very excited with all the new development that is taking place in this field, and will be writing more about our experience with these tools over the coming years.
 </p>

<p>What we ended up with has met all of the goals that we set out to achieve.  We have successfully abstracted scaling, monitoring, protocol presentation and metric aggregation, allowing us to focus entirely on delivering functionality to our customers.  Now that our customers include MLG, this means that we'll be rolling out some of the biggest and baddest applications in the gaming community, with confidence and reliability.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Jun 24</div></div><div class="blog-content"><h2><a href="/blog/2010/06/24/setting-up-a-rails-3-development-environment/">Setting Up a Rails 3 Development Environment</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>Getting started with Rails 3 development is a very straightforward process, granted you have the prerequisite version of Ruby installed on your system. <a href="http://rvm.beginrescueend.com">Ruby Version Manager</a> (RVM) is a utility that makes it very easy and painless to switch between Ruby versions while maintaining your system's stock Ruby installation. RVM not only enables you to switch between Ruby versions, but also maintains distinct gem sets specific to each of those versions which is very helpful when testing out new Rails environments.</p>

<p>Before we jump into setup, first a bit about our pre-Rails3 environment:</p>

<ul>
  <li>Mac OS X 10.5.8</li>
  <li>ruby 1.8.6 (2009-06-08 patchlevel 369) [universal-darwin9.0] (stock)</li>
  <li>RubyGems 1.3.7</li>
  <li>Various older versions of Rails (2.3.8, 2.3.5, 2.3.4, 2.3.2, 2.2.2, 2.1.1, 2.1.0, 2.0.2, 1.2.6, 1.2.3)</li>
</ul>

<p>We will be installing the latest release of Rails which, as of this writing, is Rails 3 beta4.
 We will also complete setup using the latest version of Ruby 1.9.
 The minimal version of Ruby 1.9 required for this Rails release is 1.9.2.
 To complete setup with Ruby 1.8.7, consult the <a href="http://guides.rails.info/3_0_release_notes.html#rails-3-requires-at-least-ruby-187">Rails 3 release notes</a> for the minimal version requirements.</p>

<p>The basic installation steps are as follows:
1. Install RVM (Ruby Version Manger)
2. Install Ruby 1.9.2
3. Install Rails3 beta4
4. Profit!</p>

<p>To install, issue the following commands in a terminal window:
1. <code>bash &lt; &lt;( curl http://rvm.beginrescueend.com/releases/rvm-install-head )</code>
  - This is the preferred RVM installation method as described in the <a href="http://rvm.beginrescueend.com/rvm/install/">RVM installation instructions</a>.</p>

<ol>
  <li><code>rvm install 1.9.2-head</code></li>
  <li><code>rvm 1.9.2-head</code></li>
  <li><code>gem install rails --pre</code></li>
</ol>

<p>Installation of the rails gem should also install it's respective dependencies:
[05:16:50][tquackenbush@TQuackenbush ~]$ gem list</p>

<p>*** LOCAL GEMS ***
 never
 abstract (1.0.0)
 actionmailer (3.0.0.beta4)
 actionpack (3.0.0.beta4)
 activemodel (3.0.0.beta4)
 activerecord (3.0.0.beta4)
 activeresource (3.0.0.beta4)
 activesupport (3.0.0.beta4)
 arel (0.4.0)
 builder (2.1.2)
 bundler (0.9.26)
 erubis (2.6.5)
 i18n (0.4.1)
 mail (2.2.5)
 mime-types (1.16)
 polyglot (0.3.1)
 rack (1.1.0)
 rack-mount (0.6.4)
 rack-test (0.5.4)
 rails (3.0.0.beta4)
 railties (3.0.0.beta4)
 rake (0.8.7)
 rdoc (2.5.8)
 thor (0.13.6)
 treetop (1.4.8)
 tzinfo (0.3.22)
 To test out your new installation, try creating a new bare bones Rails 3 application like so:
1. <code>rails new test_app</code>
2. <code>cd test_app</code>
3. <code>bundle install</code>
  - Bundler is the new default dependency manager in Rails 3, and will install any missing gems required by the project.
- In my case, this was 'sqlite3-ruby (1.3.0)'</p>

<ol>
  <li><code>rails server</code></li>
</ol>

<p>As in Rails 2, this should launch a WEBrick server instance listening on localhost port 3000 with output similar to:
=&gt; Booting WEBrick
 =&gt; Rails 3.0.0.beta4 application starting in development on http://0.0.0.0:3000
 =&gt; Call with -d to detach
 =&gt; Ctrl-C to shutdown server
 [2010-06-23 16:54:06] INFO WEBrick 1.3.1
 [2010-06-23 16:54:06] INFO ruby 1.9.2 (2010-06-22) [i386-darwin9.8.0]
 [2010-06-23 16:54:06] INFO WEBrick::HTTPServer#start: pid=6529 port=3000
 And that's it! You're all ready to go with Rails 3!</p>

<p><strong>Update: June 25th, 2010</strong> (David Czarnecki)</p>

<p>I ran into an issue on one system where rvm and Ruby 1.9.2 were correctly installed on the system, but Rails 3 would not install. The installation would go as follows.
 &gt;
machine-name:~ dczarnecki$ gem install rails –pre
 WARNING:  RubyGems 1.2+ index not found for:</p>

<p>RubyGems will revert to legacy indexes degrading performance.
I blew away the ~/.gemrc file and Rails 3 installed successfully. YMMV.</p>

<p><strong>Update: June 29th, 2010</strong> (Joshua Childs)
 Ran into two issues with with dependencies while getting setup on my Ubuntu workstation.</p>

<p>First was while problem I ran into was while following the installation steps.</p>

<p>[source language='bash']
 # Command:
 josh@jagar-tharn:~$ rvm install 1.9.2-head</p>

<p># Response:
 fail: bison is not available in your path. Please ensure it exists before compiling from head.</p>

<p># Solution:
 sudo apt-get install bison
```</p>

<p>And the second problem I ran into was while using bundle to setup my dependencies. My workstation did not have sqlite3 installed.</p>

<p>[source language='bash']
 # Command:
 josh@jagar-tharn:~/projects/test_app$ bundle install</p>

<p># Response:
 …
 Using rails (3.0.0.beta4) from bundler gems
 Installing sqlite3-ruby (1.3.0) from rubygems repository at http://rubygems.org/ with native extensions /home/josh/.rvm/rubies/ruby-1.9.2-head/lib/ruby/1.9.1/rubygems/ext/builder.rb:46: warning: Insecure world writable dir /usr/local/libevent/ in PATH, mode 040777
 /home/josh/.rvm/rubies/ruby-1.9.2-head/lib/ruby/1.9.1/rubygems/installer.rb:483:in `rescue in block in build_extensions': ERROR: Failed to build gem native extension. (Gem::Installer::ExtensionBuildError)</p>

<p>/home/josh/.rvm/rubies/ruby-1.9.2-head/bin/ruby extconf.rb
 checking for sqlite3.h… no
 sqlite3.h is missing. Try 'port install sqlite3 +universal' or 'yum install sqlite3-devel'
 *** extconf.rb failed ***
 Could not create Makefile due to some reason, probably lack of
 necessary libraries and/or headers. Check the mkmf.log file for more
 details. You may need configuration options.</p>

<p>Provided configuration options:
 –with-opt-dir
 –without-opt-dir
 –with-opt-include
 –without-opt-include=${opt-dir}/include
 –with-opt-lib
 –without-opt-lib=${opt-dir}/lib
 –with-make-prog
 –without-make-prog
 –srcdir=.
 –curdir
 –ruby=/home/josh/.rvm/rubies/ruby-1.9.2-head/bin/ruby
 –with-sqlite3-dir
 –without-sqlite3-dir
 –with-sqlite3-include
 –without-sqlite3-include=${sqlite3-dir}/include
 –with-sqlite3-lib
 –without-sqlite3-lib=${sqlite3-dir}/lib
 …</p>

<p># Solution:
 josh@jagar-tharn:~/projects/test_app$ sudo apt-get install sqlite3
 josh@jagar-tharn:~/projects/test_app$ sudo apt-get install libsqlite3-dev
```</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">May 25</div></div><div class="blog-content"><h2><a href="/blog/2010/05/25/my-testing-environmen/">My Rails dev environment</a></h2><div class="blog-author">By <strong>Brian Corrigan</strong></div><div class="blog-body"><p>I love reading about the way people set up their development environments. I recently started working on a new project at work and had to set everything up from scratch. Here's my setup.</p>

<p>First, install some gems.</p>

<p>```
# On all systems
sudo gem install ZenTest
sudo gem install redgreen
sudo gem install autotest-rails
sudo gem install shoulda
sudo gem install factory_girl</p>

<h1 id="only-on-my-osx-machine">Only on my OSX machine</h1>
<p>sudo gem install autotest-growl
sudo gem install autotest-fsevent</p>

<h1 id="only-on-my-ubuntu-machine">Only on my Ubuntu machine</h1>
<p>sudo gem install test_notifier
sudo apt-get install libnotify-bin
```</p>

<p>Next, I setup my ~/.autotest file:</p>

<p>```ruby
#!/bin/ruby
require 'redgreen/autotest'
require 'autotest/timestamp'
require "autotest/restart"</p>

<h1 id="only-ubuntu">Only Ubuntu</h1>
<p>require "test_notifier/autotest"</p>

<h1 id="only-osx">Only OSX</h1>
<p>require "autotest/growl"
require 'autotest/fsevent'</p>

<h1 id="all-machines">All machines</h1>
<p>Autotest.add_hook :initialize do |autotest|
  %w{.git .svn .hg .DS_Store ._* vendor tmp log doc}.each do |exception|
    autotest.add_exception(exception)
  end
end
```</p>

<p>Also, I really like git instaweb. I sent it to G, our brilliant (ex)intern and he likes it too. To start it I use:</p>

<p><code>
git instaweb -d webrick --start
</code></p>

<p>You can automate this by adding the following to your ~/.gitconfig:</p>

<p><code>
[instaweb]
httpd=webrick
</code></p>

<p>You can also add a port option (port=8000) if you want.</p>

<p>Also, to stop instaweb, from the git repo that you started instaweb from run:</p>

<p><code>
git instaweb stop
</code></p>

<p>Finally, I tend to branch a lot and store them server-side. I like tracking branches to automatically push/pull changes to a branch from a remote repository. All this really does is add a few lines to your .gitconfig, but hey, who doesn't like a shortcut.</p>

<p><code>
git branch --track branch remote
</code></p>

<p>Last but not least, the Cheat gem is awesome. It's like man, but distilled to the things you'll actually use. (It's actually where I read about instaweb) Use it!</p>

<p><code>
sudo gem install cheat
</code></p>

<p>So in general, that's the interesting bits of my environment. How about yours?</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">May 17</div></div><div class="blog-content"><h2><a href="/blog/2010/05/17/browsers-and-status-204/">Browsers and Status: 204</a></h2><div class="blog-author">By <strong>Jason LaPorte</strong></div><div class="blog-body"><p><em>Trivia: The HTTP RFC asks browsers to NOT update the browser page when 204 status codes are received.</em></p>

<p>Holy crap is this visually confusing; even Firebug returns nothing! That said, it's a perfect example of why performing only in-browser testing fails miserably. Functional tests.. use em!</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">May 13</div></div><div class="blog-content"><h2><a href="/blog/2010/05/13/rubyreversibleencryption/">Ruby Reversible Encryption</a></h2><div class="blog-author">By <strong>An Engineer</strong></div><div class="blog-body"><p>It's been awhile since I had to do anything with reversible encryption. Here's a working sample using AES.</p>

<p>```ruby
#/usr/bin/ruby
require 'openssl'
require "base64"
require 'uri'</p>

<h1 id="first-lets-encrypt-the-string">First lets encrypt the string!</h1>
<p>plaintext = 'Super secret message'</p>

<h1 id="create-the-cipher">Create the cipher</h1>
<p>cipher = OpenSSL::Cipher::Cipher.new("aes-256-cbc")
cipher.encrypt # Tell OpenSSL to operate in encrypt mode
puts "Cipher wants a key that is #{cipher.key_len}"
key = '01234567890123456789012345678901'
cipher.key = key</p>

<p>puts "Cipher wants an initialization vector that is #{cipher.iv_len}"
cipher.iv = iv = cipher.random_iv # Create and set a random initialization vector</p>

<h1 id="encrypted">Encrypted</h1>
<p>encrypted = cipher.update(plaintext) + cipher.final
encrypted = iv + encrypted # Send along the IV</p>

<h1 id="lets-pretty-up-the-encrypted-string">Lets pretty up the encrypted string</h1>
<p>encrypted = Base64.encode64(encrypted)
#encrypted = URI.escape(encrypted, Regexp.new("[^#{URI::PATTERN::UNRESERVED}]"))
encrypted = URI.escape(encrypted)</p>

<h1 id="now-lets-unencrypt-it-first-start-with-a-new-cipher">Now lets unencrypt it, first start with a new cipher</h1>
<p>cipher = OpenSSL::Cipher::Cipher.new("aes-256-cbc")
cipher.decrypt # Use SSL in decrypt mode
cipher.key = key
encrypted = URI.unescape(encrypted)
encrypted = Base64.decode64(encrypted)
cipher.iv = encrypted.slice!(0,16) # Remove the IV from the encrypted data
decrypted = cipher.update(encrypted) + cipher.final</p>

<h1 id="test">Test</h1>
<p>puts 'The original was '+ plaintext
puts 'Encrypted that was ' + encrypted
puts 'Decrypted we have ' + decrypted
```</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Apr 28</div></div><div class="blog-content"><h2><a href="/blog/2010/04/28/its-my-gem-in-a-box/">It's My Gem In A Box </a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>Hey developers, I got something real important to give you. So just sit down, and listen.</p>

<p>We recently started a number of projects, each of which will require the use of a common library. So, here's how it went down:</p>

<p>* Create the common library as a gem using the <a href="http://github.com/technicalpickles/jeweler">jeweler</a> tool.</p>

<p>* Install <a href="http://tomlea.co.uk/posts/gem-in-a-box/">Gem in a Box</a> to allow the gem to be downloaded internally by our developers using gem install.</p>

<p>* Upload the common library gem.</p>

<p>BLAMMO! Now every developer can pull my gem ;)</p>

<p>But seriously, "Gem in a Box" is awesome and a great way to share gems internally at your office.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Apr 19</div></div><div class="blog-content"><h2><a href="/blog/2010/04/19/packaging-for-pleasure/">Packaging For Pleasure</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>Let me be more explicit and say I'm going to be talking about Rails application packaging. Sorry, I needed a good post title for the lulz and the page views.</p>

<p>There are a few rake tasks that I've been using more and more now that all of our applications are running in a shared, virtual enviroment. They are:</p>

<ul>
  <li>rake -T     # -T, –tasks [PATTERN]            Display the tasks (matching optional PATTERN) with descriptions, then exit.</li>
</ul>

<p>Everyone should know and use this task at least once in their Rails-development life.</p>

<ul>
  <li>rake rails:freeze:gems   # Lock this application to the current gems (by unpacking them into vendor/rails)</li>
  <li>rake gems:unpack   # Unpacks all required gems into vendor/gems.</li>
  <li>rake gems:unpack:dependencies   # Unpacks all required gems and their dependencies into vendor/gems.</li>
</ul>

<p>So, once I've created my project with "rails [project name]", then next thing I do is "rake rails:freeze:gems" to freeze the Rails gems. I'll enumerate the application's dependencies in the environment.rb file and then run "rake gems:unpack" to make sure those dependencies exist with the application. Example:</p>

<p><code>ruby
config.gem 'will_paginate', :version =&gt; '2.3.11', :source =&gt; 'http://gemcutter.org'
config.gem 'factory_girl', :version =&gt; '1.2.4', :source =&gt; 'http://gemcutter.org'
config.gem 'fakeweb', :version =&gt; '1.2.8', :source =&gt; 'http://gemcutter.org'
</code></p>

<p>Why do I like this approach? In a shared environment, it means we don't have to have our systems folks install any dependencies for our application to run making the application self-contained. This is mostly fine for gems that don't have an explicit native component. Also, in being explicit about versions of the gems that an application is using, we do not run the risk of chasing a moving target. Again, in a shared environment, if someone updates a gem on the system, it's probably not an issue until the one time it is and you're being called at 3 AM that the application is down because of a gem incompatibility change.</p>

<p>That's it. Any other packaging dos and don't?</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Apr 9</div></div><div class="blog-content"><h2><a href="/blog/2010/04/09/as-it-turns-out-faking-it-is-ok/">As It Turns Out, Faking It Is OK</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>This post is totally SFW. That's all your going to get in this teaser.</p>

<p><img alt="when_harry_met_sally" title="when_harry_met_sally" alt="" width="334" height="286" src="/assets/images/uploads/2010/04/themarketingblog_e_a001438922.JPG" /></p>

<p>I just inherited an application and was adding some tests and noticed that one of the tests was randomly failing. As I dug in more, this particular controller test, in executing the controller's index method, was actually calling out on the intertubes to request some data. For an integration test that's probably OK, but my view is that unit and functional tests should be self-contained.</p>

<p>Enter <a href="http://github.com/chrisk/fakeweb">Fakeweb</a>.</p>

<p>"FakeWeb is a helper for faking web requests in Ruby. It works at a global level, without modifying code or writing extensive stubs."</p>

<p>3 lines of code later and I have a self-contained functional test that works with real data.</p>

<p>```ruby
def setup
  FakeWeb.allow_net_connect = false
end</p>

<p>def teardown
  FakeWeb.allow_net_connect = true
end</p>

<p>test "should get index" do
  FakeWeb.register_uri(:get, 'http://my.real.url.on.the.internets.com', :body =&gt; File.join(File.dirname(<strong>FILE</strong>), '../fakeweb', 'some-file.xml'), :content_type =&gt; "text/xml")</p>

<p>get :index
  assert_response :success</p>

<p>…</p>

<p>```</p>

<p>All I needed to do was simply register the URI that was being referenced in my test, provide a valid (or invalid depending on the test) response, and my test will never try to access the real internet.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Apr 7</div></div><div class="blog-content"><h2><a href="/blog/2010/04/07/the-importance-of-having-a-fast-test-suite/">The Importance of Having a (Fast) Test Suite</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>Speed is the name of the game. Or is it?</p>

<p>I was adding another project to our Continuous Integration (CI) server that runs the test suite for a project after code is checked in and started noticing the time it takes to build certain projects. A few interesting statistics for you to noodle on.</p>

<p>Average build time: ~32 seconds</p>

<p>Max build time: 1 hour and 48 minutes</p>

<p>There are approximately 18 projects that get built through CI and many other projects that have not been setup for CI.</p>

<p>What does this tell us? Testing is not an impediment to development because it takes too long to run tests. As most test suites run in less than a minute, not running the test suite is not an option for our developers. And if you don't, CI sends an e-mail to the team letting everyone know you broke the build. And since our post-commit hooks for SVN and git notify our Campfire room each time code is committed, chances are you're going to get an earful in Campfire telling you to fix the build because your last commit broke the build.</p>

<p><img alt="chet_weird_science" title="chet_weird_science" alt="" width="495" height="264" src="/assets/images/uploads/2010/04/Picture-17-cb856a7c.png" /></p>

<p>I'm glad nearly all of our projects have test suites that run quickly, but I also have a practical view on test suites. <strong>Above all, if nothing else, I want a test suite to exist.</strong> I want it to be there so that when I'm adding code to the repository, the test suite is looking at me asking for more.</p>

<p><img alt="More tests please!" title="More tests please!" alt="" width="188" height="203" src="/assets/images/uploads/2010/04/Picture-16-f97d6155.png" /></p>

<p>About that project that takes 1 hour and 48 minutes to build? Right. Guitar Hero. It's a BIG project. It's over 3 years old. There is a LOT of code. We test A LOT of systems, e.g. accounts, clans, tournaments, leaderboards, game configurations, game integration processing, etc. I'm OK with it taking that long to run the test suite. We have development practices that we follow for running sub-sections of the test suite when we touch the application to test our new code.</p>

<p>To summarize:</p>

<ul>
  <li>Ensure your projects have a test suite</li>
  <li>Run a Continuous Integration (CI) server for your projects for when developers forget to run the test suite before committing code</li>
  <li>Ensure your projects have a test suite</li>
  <li>Ensure your projects have a test suite</li>
  <li>Ensure your projects have a test suite</li>
  <li>Make sure developers know how to run part of the test suite for long-running test suites</li>
  <li>Ensure your projects have a test suite</li>
</ul>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Mar 30</div></div><div class="blog-content"><h2><a href="/blog/2010/03/30/all-parsers-are-not-created-equal/">All Parsers Are Not Created Equal</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>This is a post about <a href="http://en.wikipedia.org/wiki/Xml">XML</a> and <a href="http://en.wikipedia.org/wiki/JSON">JSON</a>.</p>

<p>We recently came across a bottleneck in one of our applications that grabs data from a content repository. A large part of the bottleneck had to do with caching of data from the content repository, or lack thereof. A small part of the bottleneck has to do with parsing of XML data as the application grabs XML feeds from the content repository and parses it to display data within the application. Novel idea using XML as a communication mechanism between 2 applications? You betcha.</p>

<p>In any event, boring machine name aside, I decided to benchmark the data parsing via JSON, Hpricot, and Simple-RSS.</p>

<p><code>ruby
David-Czarneckis-iMac:application-playground dczarnecki$ ruby parsing-benchmarking.rb
"Benchmarking JSON"
"    JSON document: /Users/dczarnecki/projects/parsing-benchmarking/sample_json_document.json, Size: 161574"
"    JSON::Ext::ParserJSON::Ext::Generator"
"    Benchmarked JSON parse for 20x (average): 0.0121459603309631"
"Benchmarking Hpricot"
"    XML document: /Users/dczarnecki/projects/parsing-benchmarking/sample_photo_rss_document.rss, Size: 162644"
"    Benchmarked XML parse for 20x (average): 0.00232400894165039"
"Benchmarking Simple-RSS"
"    XML document: /Users/dczarnecki/projects/parsing-benchmarking/sample_photo_rss_document.rss, Size: 162644"
"    Benchmarked XML parse for 20x (average): 1.78787769079208"
David-Czarneckis-iMac:application-playground dczarnecki$
</code></p>

<p>The numbers are interesting. Here is my opinion on the results:</p>

<ul>
  <li>
    <p>Hpricot is the fastest at parsing a big XML document. You have to use XPath to get at the elements in the document. XPath is, for me, non-intuitive and you sacrifice a bit in terms of readability of the code.</p>
  </li>
  <li>
    <p>JSON is the second fastest at parsing a big JSON document. Also, you have a four letter acronym technology integrated into your application, and let's finally admit it, size matters. For me, you gain intuitive access to the underlying data and more readability of the code.</p>
  </li>
  <li>
    <p>Simple-RSS is slow.</p>
  </li>
  <li>
    <p>XML output from our content repository doesn't give us paged access to the content, but the JSON API in the content repository does give us paged access to the content. With the XML output, we have to suck down a firehose and slice it up appropriately leading to a bunch of flackery with caching the parsed document.</p>
  </li>
</ul>

<p>If you're looking for a better read, then check out the following book, "Paint It Black: A Guide to Gothic Homemaking".</p>

<p><a href="http://www.amazon.com/Paint-Black-Guide-Gothic-Homemaking/dp/1578633613/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1269982528&amp;sr=1-1"><img alt="Paint it Black" title="Paint it Black" alt="" width="300" height="300" src="/assets/images/uploads/2010/03/41Jbbh8d2SL._BO2204203200_PIsitb-sticker-arrow-clickTopRight35-76_AA300_SH20_OU01_-3b264d01.jpg" /></a></p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Mar 11</div></div><div class="blog-content"><h2><a href="/blog/2010/03/11/vbulletin-and-nginx/">vBulletin and NGINX</a></h2><div class="blog-author">By <strong>Jason LaPorte</strong></div><div class="blog-body"><p>It's no secret that Agorian systems folk favor <a href="http://nginx.org/">NGINX</a> for our web serving needs. We've written about it a lot before. Therefore, it should be no surprise that we end up making a lot of things designed to work on <a href="http://httpd.apache.org/">Apache</a> work on NGINX. (We've also written about that before, come to think of it…)</p>

<p>One example is <a href="http://www.vbulletin.com/">vBulletin</a>. A number of Agora's sites are powered by the forum software, which comes with rewriting rules for Apache's <a href="http://httpd.apache.org/docs/2.0/mod/mod_rewrite.html">mod_rewrite</a> and <a href="http://www.iis.net/">IIS</a>… but not NGINX.</p>

<p>So, if you're interested in setting up vBulletin behind NGINX (and are using the advanced URL rewriting, like we are), you can find a sample configuration for doing so  <a href="http://files.agoragames.com/jason/vb-nginx.txt">here</a>.</p>

<p>Let us know if you have any questions!</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Mar 8</div></div><div class="blog-content"><h2><a href="/blog/2010/03/08/devon-in-print/">Devon in print</a></h2><div class="blog-author">By <strong>Devon Smith</strong></div><div class="blog-body"><p>Our very own Devon Smith (Agora's multi-talented QA Lead) had an article published in this month's T.E.S.T Magazine. You can see her article online ( <a href="http://www.testmagazine.co.uk/2010/03/keep-the-user-in-mind/">http://www.testmagazine.co.uk/2010/03/keep-the-user-in-mind/</a>), or buy it in print later this month.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Mar 8</div></div><div class="blog-content"><h2><a href="/blog/2010/03/08/bzr-to-git-migration/">Bzr to Git Migration</a></h2><div class="blog-author">By <strong>An Engineer</strong></div><div class="blog-body"><p>When I joined Agora, one of the first things I did was talk up <a href="http://git-scm.com">git</a> and how it'll cure cancer, AIDS, and solve world peace. All at once. What that means for me is I've basically been tasked with the job of migrating anything that's not git to git.</p>

<p>For some things these kinds of migration are first class citizens. Conveniently SVN, our old VCS is one of those. One of my new migrations was, less conveniently, <a href="http://bazaar.canonical.com/">Bazaar</a>. Now we have nothing against Bazaar at Agora. I mean my main personal open source project, <a href="http://exaile.org/">Exaile</a>, uses Bazaar. But we agreed we would rather only have one VCS in house.</p>

<p>After looking around and trying some fancy tools that didn't work (read: tailor), I stumbled on a really quick solution that seems like it does everything necessary. Both Git and Bazaar (via plugins) support the fast-import/export format. I'm not sure about the mystic ways of how this format works but I do know it made my Bazaar repository a Git repository, and that makes me pleased.</p>

<h2 id="getting-the-bzr-plugin">Getting the bzr plugin</h2>
<p>The first step would be to get the fast-import plugin for Bazaar from the launchpad mirror.
<code>
 mkdir -p ~/.bazaar/plugins
 cd ~/.bazaar/plugins
 bzr clone lp:bzr-fastimport fastimport
</code>
 You can make sure it installed properly using a <code>bzr fast-export --help</code> and ensure that it doesn't complain.
## Copy the repository
Now that we have all the tools, time to copy it over
<code>
 mkdir ~/project.git
 cd ~/project.git
 git init
 bzr fast-export --plain ~/path/to/bzr/branch | git fast-import
 git checkout master # only needed for a non-bare repository, like I made above
</code></p>

<p>Wait a little while (or a long while if you're testing the above code on a netbook for some reason like me). And that should be it.</p>

<p>I'm not sure how well this works with multiple Bazaar branches. There may be some crazy <code>--flags</code> on each side to make it work but running the code I put above on a full repo makes fast-export complain that I'm not pointing it to a valid branch. Please give us your comments if you know how to do this :).</p>

<p><strong>Update:</strong> Found out it was .bazaar not .bzr. My bad.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Feb 23</div></div><div class="blog-content"><h2><a href="/blog/2010/02/23/experimenting-with-redis/">Experimenting with Redis</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>Yesterday I started looking at ways to do inter-application communication. In a number of projects we've done here at Agora Games, we've used queues to make that happen. <a href="http://code.google.com/p/redis/">Redis</a> has been on my radar for awhile now, but yesterday I drove my Chevy to the levee and guess what? The levee is NOT dry people. I mean, who drinks rye anyway these days? Old people.</p>

<p>Right, <a href="http://code.google.com/p/redis/">Redis</a>.</p>

<p>"Redis is an advanced key-value store. It is similar to memcached but the dataset is not volatile, and values can be strings, exactly like in memcached, but also lists, sets, and ordered sets. All this data types can be manipulated with atomic operations to push/pop elements, add/remove elements, perform server side union, intersection, difference between sets, and so forth. Redis supports different kind of sorting abilities."</p>

<p>I was particularly interested in the support in Redis for lists, which would allow me to have one application push stuff into the datastore and allow for another application to pull stuff from the datastore. A datastore that could operate as a queue? I guess this is as close as we're going to get to flying cars in 2010. Redis is also supposed to be wicked fast and there are a number of libraries available in your programming language of choice with which to communicate with Redis.</p>

<p>Redis setup was trivial and "just worked".</p>

<p>After starting the Redis server, I could just prototype in script/console.</p>

<p>Here we go:</p>

<p><code>ruby
&gt;&gt; redis_queue = Redis.new
=&gt; #&lt;Redis:0x222df9c @thread_safe=nil, @logger=nil, @password=nil, @timeout=5, @db=0, @sock=nil, @host="127.0.0.1", @port=6379&gt;
&gt;&gt; redis_queue.push_tail 'strings', 'string 1'
=&gt; "OK"
&gt;&gt; redis_queue.push_tail 'strings', 'string 2'
&gt;&gt; "OK"
&gt;&gt; redis_queue.list_length('strings')
=&gt; 2
&gt;&gt; redis_queue.list_range('strings', 0, -1)
=&gt; ["string 1", "string 2"]
&gt;&gt; some_string = redis_queue.pop_head('strings')
=&gt; "string 1"
&gt;&gt; r.list_range('strings', 0, -1)
=&gt; ["string 2"]
&gt;&gt; r.list_length('strings')
=&gt; 1
&gt;&gt; quit
</code></p>

<p><a href="http://code.google.com/p/redis/wiki/CommandReference">There are quite a few commands that make Redis even more awesome, but for now I'm sold</a>. (If using an entire sentence as a link is wrong then I don't want to be right)</p>

<p>Also, I know of <a href="http://github.com/defunkt/resque#readme">Resque</a>, "a Redis-backed library for creating background jobs, placing those jobs on multiple queues, and processing them later." If I ever feel like driving the Mercedes Benz of flying cars, I'll use it.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Feb 23</div></div><div class="blog-content"><h2><a href="/blog/2010/02/23/watching-trees/">Watching Trees</a></h2><div class="blog-author">By <strong>Jason LaPorte</strong></div><div class="blog-body"><p>As a SysAdmin, my job more-or-less exists by knowing miscellaneous arcana that most software engineers aren't aware of.</p>

<p>When a particular co-worker here at Agora has a problem with his Linux machine, I provide advice and show him how to fix it. Some months after he had joined Agora, I discovered that after each troubleshooting session, he copy-and-pastes the entire text terminal log into a text file that he keeps on his desktop. He has dozens of transcripts at this point; I bet if I were to look through it, it would read something like the Tao te Ching or Bhagavad Gita, only concerning UNIX instead of right living.</p>

<p>(Of course, there's not much of a difference between UNIX and right living, but that's a topic for another day.)</p>

<p>In the spirit of allowing you to build your own little collection, here is a simple trick that came in handy to me yesterday.</p>

<p>Last night, the cron jobs powering one of our managed sites stopped running. I had stopped them, cleaned up, and restarted them, but I wanted to watch the system and see if they had started running again so I could monitor that they were doing their job.</p>

<p>UNIX has a well-known command called " <a href="http://linux.die.net/man/1/top">top</a>," which shows superlative processes running on your system: which ones are consuming the most CPU time, which ones are consuming the most RAM, which ones have been running the longest, and so on. It's a very useful tool, but if you're trying to track down processes over time that don't necessarily consume very many resources, then it's not the tool you're looking for.</p>

<p>However, our Linux distribution (and, indeed, most others) provide a useful graphical tool for mapping the current state of the system: " <a href="http://linux.die.net/man/1/pstree">pstree</a>." This command will give you a list of processes (much like the " <a href="http://linux.die.net/man/1/ps">ps</a>" command), except that instead of generating a list, it will draw a little tree showing the state of the system. This is perfect for seeing exactly what is going on: which daemons are running, who is on the system and what they're executing, and so on. However, it doesn't show you what is happening over time; it merely lists what is happening at this moment.</p>

<p>However, our Linux distribution (and, indeed, most others) provides yet another useful tool: " <a href="http://linux.die.net/man/1/watch">watch</a>." It runs a program every 2 seconds (by default) and displays the result to your screen. This allows you to make a ghetto clock by writing something like "watch <a href="http://linux.die.net/man/1/date">date</a>;" in our case, we could make a ghetto graphical "top" by writing the simple "watch pstree." You can now watch your virtual trees rustle in the wind.</p>

<p>It kept us on top of the cron job, and things were back to normal in no time.</p>

<p>For more information, RTFM. :)</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Feb 22</div></div><div class="blog-content"><h2><a href="/blog/2010/02/22/and-now-for-some-couchdb/">And now for some couchdb</a></h2><div class="blog-author">By <strong>Jason LaPorte</strong></div><div class="blog-body"><p>I had occasion tonight to give a quick demo of CouchDB.  This is so simple its almost not worth blogging about, but hey, good software is <strong><em>supposed</em></strong> to be simple.</p>

<p><strong>Install</strong>
 On your Mac:</p>

<p><code>
 sudo port install couchdb
 sudo launchctl load -w /Library/LaunchDaemons/org.apache.couchdb.plist
</code></p>

<p>On Ubuntu:</p>

<p><code>
 sudo apt-get install couchdb
</code></p>

<p>You're done; now to play.</p>

<p><strong>Futon Admin Interface</strong>
 This allows you to create a DB, create records, etc.</p>

<ol>
  <li>Open http://localhost:5984/_utils/</li>
  <li>…</li>
  <li>Prosper</li>
</ol>

<p><strong>Using our old friend <em>curl</em></strong></p>

<p><code>
 curl -X PUT http://localhost:5984/mlg/ #create a db
 curl -X GET http://localhost:5984/mlg/ #get a whole bunch of info about the db
 curl -X POST http://localhost:5984/mlg/ -H "Content-Type:application/json" -d '{"body": "Here is a paragraph"}' #create a record
</code></p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Jan 29</div></div><div class="blog-content"><h2><a href="/blog/2010/01/29/getting-started-with-data_fabric/">Getting started with data_fabric</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>The <a href="http://github.com/mperham/data_fabric">data_fabric</a> gem "provides flexible database connection switching for ActiveRecord". If you're not concerned with database sharding, you might want to skip this blog post. Or not. Either way, I'm not going to be offended.</p>

<p>I have a requirement that certain data in an application that I'm developing will probably have to be sharded because, if you'll excuse my English, there will a "shit ton" of data. This only affects one model out of the few models I have in the application. I don't have a requirement that the data will be replicated (which is another feature supported in <code>data_fabric</code>), so I'm not going into that here. In any event, here is a rundown of how I got started developing and testing with <code>data_fabric</code>.</p>

<ul>
  <li>Configure the <code>data_fabric</code> gem in your <code>config/environment.rb</code> file.</li>
</ul>

<p><code>ruby
config.gem 'data_fabric'
</code></p>

<ul>
  <li>In your model(s), decide on which column or how the data is going to be shared.</li>
</ul>

<p><code>ruby
data_fabric :replicated =&gt; false, :shard_by =&gt; :initial_code
</code></p>

<p>In this case, inital_code is a method that looks at a piece of the model's data and gives me the correct shard.</p>

<ul>
  <li>Setup the database shards in your <code>config/database.yml</code> file. I actually setup only one shard for development and testing environments to make things easier. I'm just including the one for the test environment here. You can read on the <code>data_fabric</code> site about the naming convention for sharded database connections.</li>
</ul>

<p>```yaml
test:
adapter: mysql
encoding: utf8
reconnect: false
database: myapp_test
pool: 5
username: root
password:</p>

<h1 id="this-is-the-database-shard">This is the database shard</h1>
<p>initial_code_testenv_test:
adapter: mysql
encoding: utf8
reconnect: false
database: myapp_test_testenv
pool: 5
username: root
password:
```</p>

<ul>
  <li>In <code>config/initializers/my_app_model.rb</code>, I actually stub out the initial_code method to return a single value for the development and test environments. This is merely convenience so I don't have to include every single database shard for development and testing.</li>
</ul>

<p>```ruby
require 'mocha'</p>

<p>if 'development'.eql?(RAILS_ENV)
  PromotionCode.stubs(:initial_code).returns('devenv')
end</p>

<p>if 'test'.eql?(RAILS_ENV)
  PromotionCode.stubs(:initial_code).returns('testenv')
end
```</p>

<ul>
  <li>I copied part of the Rakefile from the <code>data_fabric</code> gem to actually be able to migrate the database for the sharded database connections. This was definitely missing from the <code>data_fabric</code> README.</li>
</ul>

<p>```ruby
require 'fileutils'
include FileUtils::Verbose</p>

<p>namespace :db do
  task :migrate do
    require 'erb'
    require 'logger'
    require 'active_record'</p>

<pre><code>reference = YAML::load(ERB.new(IO.read("config/database.yml")).result)
env = RAILS_ENV = ENV['RAILS_ENV'] || 'development'

ActiveRecord::Base.logger = Logger.new(STDOUT)
ActiveRecord::Base.logger.level = Logger::WARN
ActiveRecord::Base.configurations = reference.dup
old_config = reference[env]
reference.each_key do |name|
  next unless name.include? env
  next if name.include? 'slave' # Replicated databases should not be touched directly

  puts "Migrating #{name}"
  ActiveRecord::Base.clear_active_connections!
  ActiveRecord::Base.configurations[env] = reference[name]
  ActiveRecord::Base.establish_connection RAILS_ENV
  ActiveRecord::Migration.verbose = ENV["VERBOSE"] ? ENV["VERBOSE"] == "true" : true
  ActiveRecord::Migrator.migrate("db/migrate/", ENV["VERSION"] ? ENV["VERSION"].to_i : nil)
end   end end ```
</code></pre>

<ul>
  <li>In my test classes that use the sharded model, I have setup and teardown methods that activate and deactivate the shard.</li>
</ul>

<p>```ruby
def setup
  DataFabric.activate_shard(:initial_code =&gt; 'testenv')
end</p>

<p>def teardown
  MyAppModel.delete_all
  DataFabric.deactivate_shard(:initial_code =&gt; 'testenv')
end
```</p>

<p>I did find that I needed to delete all the objects in the database for the sharded model. I'm still digging into why that's the case. My ActiveRecord_fu isn't that strong I guess.</p>

<p>All in all, sharding is relatively easy with data_fabric. Pimping, however, "ain't easy." But that's for another blog post I guess.</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Jan 15</div></div><div class="blog-content"><h2><a href="/blog/2010/01/15/i-am-git-and-so-can-you/">I Am Git (And So Can You!)</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>It's amazing how a few months can change your mindset around the version control system you use. Ever since I joined Agora Games in May 2008, we have used Subversion (SVN). Subversion is a fine version control system. We have one new project using Subversion and we will probably have a few legacy projects that will always use Subversion. However, last year, one of our project teams made the switch to Git and ever since then, new projects have been using Git.</p>

<p>Looking at CruiseControl, here's the breakdown of Subversion and Git projects:</p>

<p>Subversion: 4</p>

<p>Git: 7</p>

<p>Here is what I found personally about my Git transition experience.</p>

<ul>
  <li>If you look at the simple examples or cursory blog post introductions of using Git as a version control system, you're probably not going to switch. I didn't find those examples or Git blog posts enlightening at all. I just thought to myself, "Great, Git can track changes to files just like Subversion, so why should I switch?".</li>
  <li>Git is something I can use independent of a service like GitHub locally to implement version control on projects that might never make it off of my machine.</li>
  <li>Git can be taken to the extreme where every "change" can be separated from the main branch of development and then merged at a later point. At Agora, we've taken a more balanced approach where major features go into a new branch and then are reviewed and merged back into the main branch, after which the new branch can be safely removed (e.g. replacing an authentication system).</li>
  <li>Although tools like <a href="http://www.syntevo.com/smartgit/index.html">SmartGit</a> exist, I needed to get comfortable by using Git from the command-line.</li>
  <li>There are a lot of Git commands and capabilities I haven't used yet, and that's OK.</li>
  <li>I love the idea of the Git stash, where you can scurry away local changes and revert to a clean working directory, but then recover those changes later.</li>
</ul>

<p>Git is just something you need to try. I'm no expert in Git (yet). Git's barrier to entry feels very minimal when compared to other version control systems.</p>

<p>P.S. I realize this blog post falls under the "cursory blog post introductions of using Git as a version control system" category. Whatever.</p>

<p>:)</p>
</div></div></div><div class="blog-entry"><div class="date-comments"><div class="date">Jan 4</div></div><div class="blog-content"><h2><a href="/blog/2010/01/04/scaling-ruby-and-rails-part-1/">Scaling Ruby and Rails Part 1</a></h2><div class="blog-author">By <strong>David Czarnecki</strong></div><div class="blog-body"><p>I wish scaling applications and systems these days consisted solely of " <a href="http://olabini.com/blog/2008/05/just-add-scaling/">Just Add Scaling!</a>". But you know what? It's not. I also forget where I read it, but the quote went something like, "Programming languages don't scale, architectures scale." Scaling is driven by proper iterative design, implementation and testing.</p>

<p>In a series of blog posts I want to cover how we have approached scaling out various parts of our Ruby and Rails infrastructure here at Agora Games using real-world examples on very high-traffic sites such as the Guitar Hero and Call of Duty community sites.</p>

<p>Here I'll cover the "Deep Dive". I originally came from BigCo. and there we used a concept called the "Deep Dive", which involved taking a specific requirement in combination with an approach or technology and following a thread of execution that would take you through the entire technology stack, or a "deep dive" through the system. At the end you would either prove or disprove the technology or approach. But it was done in the context of a real set of requirements.</p>

<p>The following is the e-mail (project/features names changed to protect the innocent … the important concept here is the Deep Dive, not the project/features) I sent around to our engineering team in September of last year after doing a Deep Dive on a queue system.</p>

<hr />

<blockquote>
  <p>From: David Czarnecki</p>
</blockquote>

<p>To: Engineering</p>

<p>Clearly Defined Requirement(s)</p>

<p>Ultimately, to do a deep dive correctly, you need clearly defined requirements to evaluate your technology or approach against. In the case of PROJECT X, with the use of a queue, we had the following:</p>

<p>Setup queue
 Decide event(s)
 Send to queue
 Aggregate from/to queue
 Put into message creation
 Send back to the app</p>

<p>Narrowing the Field</p>

<p>I spent a day looking at various queue packages in Ruby and other languages to understand:</p>

<p>Features - What features do we get out of the package?
 API - How easy is it to setup/create/interact with the queue from actual code?
 Aliveness - Is this an ongoing effort or was it thrown on RubyForge and ultimately abandoned?
 Community - Where is this package being used? How many developers or contributors commit to the project?
 Language - Are we expanding our technology stack by introducing a queue written in one language with an interface in another language?</p>

<p>Pork, aka The Other Other Requirements</p>

<p>And don't forget about the other "unspoken" requirements.</p>

<p>Ease of setup
 Speed
 Failsafe
 Scaling</p>

<p>At the end of the day, whichever package is picked, you want some guarantee that the package you've chosen is "good" or at least "good enough". But what if the Guarantee Fairy's a crazy glue sniffer? Next thing you know there's change missing from your dresser and your daughter's knocked up. I've seen it a hundred times. Although you've got a set of requirements that define how you're going to use a technology or approach operationally, there are still requirements that need to be addressed, even if there isn't anything formally specified.</p>

<p>Let's Get Ready To Rumble</p>

<p>I chose Sparrow and Rabbit/AMQP since these passed the "ease of setup" requirements with flying colors.</p>

<p><a href="http://code.google.com/p/sparrow/">http://code.google.com/p/sparrow/</a> - Pure Ruby</p>

<p><a href="http://hopper.squarespace.com/blog/2008/7/22/simple-amqp-library-for-ruby.html">http://hopper.squarespace.com/blog/2008/7/22/simple-amqp-library-for-ruby.html</a></p>

<p>Erlang Queue Server/Ruby interface to Queue</p>

<p>Next up it was time to prove out the feasibility of the two technologies looking at the "soft" requirements in the context of the "hard" requirements. This meant setting up the two systems to:</p>

<p>Setup queue
 Send event(s) to queue
 Aggregate from/to queue</p>

<p>The other "hard" requirements would be addressed based on the outcome of this initial sanity check.</p>

<p>2 Queues Enter, 1 Queue Leaves … Wait, what?</p>

<p>Although I wanted to use this to prove out "FEATURE X", I also wanted to address its use in "FEATURE Y". "FEATURE Y" involves converting a song file into an MP3. So I setup a test to evaluate the two systems which was:</p>

<p><code>ruby
1k, 8k, 16k, 32k, 64k messages do
  25.times do
    10000 messages do
      publish message to queue
      read message from queue
    end
  end
end
</code></p>

<p>In other words, publish 10000 messages to the queue (in one process) and read those messages from the queue (in another process), noting how long it took to publish and read. Do this 25 times to get a min/max/average time for each of the different message sizes.</p>

<p>I have attached the spreadsheet of the results which show: the larger the message, the longer it takes to publish and read from the queue. However, it also shows that Sparrow could handle the 64k messages while Rabbit/AMQP could not. Sparrow got slower to process those 10000 64k items from the queue, but it never failed as with Rabbit/AMQP. Ultimately, the deep dive was not about fixing a broken AMQP adapter.</p>

<p>The Devil is in the Details</p>

<p>One benefit of using Sparrow is that persistence is built into the server. If you take down Sparrow and there are messages on the queue, it will write those out to an SQLite3 database. Ultimately this lead me to look at the size of the field it was using for queue data which would need to be patched from its current 255 characters.</p>

<p>Conclusion</p>

<p>So, I've now got a queue server that I feel comfortable setting up and using and that can probably handle the load of data we're going to throw at it come launch. The queue server/queues were integrated into PROJECT X in the context of the "FEATURE X" to prove its feasibility in addressing that feature in a future sprint.</p>

<p>And one more thing …</p>

<p>There are tests for the various bits that make up "FEATURE X". I'm most happy with the integration test which fires up a Sparrow server, fires up a foo, creates a bar, runs the aggregator, and checks to see that a baz was created for the account (oh and then cleaning up the queue server and the subscriber). 14 LOC, but there's a lot of code that it exercises behind the scenes. And yes, it passes :)
<strong>__</strong><strong>__</strong>_____</p>

<p>So, there you go. Hopefully you have enough information to do your own Deep Dive.</p>

<p>Ultimately for FEATURE X and FEATURE Y, Sparrow more than met our needs. Advances and changes to AMQP and its associated libraries have been made which I'm sure make it a more than viable candidate. At the time however, with just getting the system to work for a day to prove out the Deep Dive, it just didn't meet our needs. Again, the point of this blog post is to talk about the Deep Dive in the larger context of its use in Scaling Ruby and Rails.</p>
</div></div></div></section><aside id="sidebar"><div class="block" id="block-archive"><h2>Blog archives</h2><h3>2014</h3><ul><li><a href="/blog/2014/11/">November 2014</a></li><li><a href="/blog/2014/10/">October 2014</a></li><li><a href="/blog/2014/08/">August 2014</a></li><li><a href="/blog/2014/07/">July 2014</a></li><li><a href="/blog/2014/06/">June 2014</a></li><li><a href="/blog/2014/04/">April 2014</a></li><li><a href="/blog/2014/03/">March 2014</a></li><li><a href="/blog/2014/02/">February 2014</a></li><li><a href="/blog/2014/01/">January 2014</a></li></ul><h3>2013</h3><ul><li><a href="/blog/2013/11/">November 2013</a></li><li><a href="/blog/2013/10/">October 2013</a></li><li><a href="/blog/2013/09/">September 2013</a></li><li><a href="/blog/2013/08/">August 2013</a></li><li><a href="/blog/2013/07/">July 2013</a></li><li><a href="/blog/2013/06/">June 2013</a></li><li><a href="/blog/2013/05/">May 2013</a></li><li><a href="/blog/2013/04/">April 2013</a></li><li><a href="/blog/2013/03/">March 2013</a></li><li><a href="/blog/2013/02/">February 2013</a></li><li><a href="/blog/2013/01/">January 2013</a></li></ul><h3>2012</h3><ul><li><a href="/blog/2012/12/">December 2012</a></li><li><a href="/blog/2012/11/">November 2012</a></li><li><a href="/blog/2012/10/">October 2012</a></li><li><a href="/blog/2012/09/">September 2012</a></li><li><a href="/blog/2012/08/">August 2012</a></li><li><a href="/blog/2012/07/">July 2012</a></li><li><a href="/blog/2012/06/">June 2012</a></li><li><a href="/blog/2012/05/">May 2012</a></li><li><a href="/blog/2012/04/">April 2012</a></li><li><a href="/blog/2012/03/">March 2012</a></li><li><a href="/blog/2012/02/">February 2012</a></li><li><a href="/blog/2012/01/">January 2012</a></li></ul><h3>2011</h3><ul><li><a href="/blog/2011/10/">October 2011</a></li><li><a href="/blog/2011/09/">September 2011</a></li><li><a href="/blog/2011/08/">August 2011</a></li><li><a href="/blog/2011/07/">July 2011</a></li><li><a href="/blog/2011/06/">June 2011</a></li><li><a href="/blog/2011/05/">May 2011</a></li><li><a href="/blog/2011/04/">April 2011</a></li><li><a href="/blog/2011/03/">March 2011</a></li><li><a href="/blog/2011/02/">February 2011</a></li><li><a href="/blog/2011/01/">January 2011</a></li></ul><h3>2010</h3><ul><li><a href="/blog/2010/12/">December 2010</a></li><li><a href="/blog/2010/11/">November 2010</a></li><li><a href="/blog/2010/10/">October 2010</a></li><li><a href="/blog/2010/09/">September 2010</a></li><li><a href="/blog/2010/08/">August 2010</a></li><li><a href="/blog/2010/07/">July 2010</a></li><li><a href="/blog/2010/06/">June 2010</a></li><li><a href="/blog/2010/05/">May 2010</a></li><li><a href="/blog/2010/04/">April 2010</a></li><li><a href="/blog/2010/03/">March 2010</a></li><li><a href="/blog/2010/02/">February 2010</a></li><li><a href="/blog/2010/01/">January 2010</a></li></ul><h3>2009</h3><ul><li><a href="/blog/2009/12/">December 2009</a></li><li><a href="/blog/2009/11/">November 2009</a></li><li><a href="/blog/2009/10/">October 2009</a></li><li><a href="/blog/2009/09/">September 2009</a></li><li><a href="/blog/2009/08/">August 2009</a></li><li><a href="/blog/2009/07/">July 2009</a></li><li><a href="/blog/2009/06/">June 2009</a></li><li><a href="/blog/2009/05/">May 2009</a></li><li><a href="/blog/2009/04/">April 2009</a></li><li><a href="/blog/2009/03/">March 2009</a></li><li><a href="/blog/2009/02/">February 2009</a></li><li><a href="/blog/2009/01/">January 2009</a></li></ul><h3>2008</h3><ul><li><a href="/blog/2008/11/">November 2008</a></li><li><a href="/blog/2008/10/">October 2008</a></li><li><a href="/blog/2008/09/">September 2008</a></li><li><a href="/blog/2008/08/">August 2008</a></li></ul></div></aside></article></div></div></div><footer><div class="outer-wrap"><div class="wrap"><div id="copyright"><img alt="Agora Games" src="/assets/images/agora-logo-agga-5548a56c.png"> <a href="http://majorleaguegaming.com/" target="_blank"><img alt="Major League Gaming" src="/assets/images/mlg-logo-white-86eb4b68.png"></a><a href="mailto:info@agoragames.com" id="email-us">Email Us</a><p>359 Broadway, Third Floor, Troy, NY 12180</p><p class="dim">&copy; 2013 Agora Games. All Rights Reserved.</p></div></div></div></footer><div class="hide"><iframe id="wufoo-iframe" src="javascript:void(0)"></iframe><a id="wufoo-thanks" href="/thanks/"></a></div><!--[if lt IE 9]>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<![endif]-->
<!--[if gte IE 9]><!-->
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<!--<![endif]-->
<script>
  if (!window.jQuery) {
    document.write('<script type="text/javascript" src="/assets/javascripts/vendor/jquery.min-199fc76d.js"><' + '/script>');
  }
</script>
<script src="/assets/javascripts/all-2f5d049e.js" type="text/javascript"></script></body></html>